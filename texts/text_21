О нейронных обыкновенных дифференциальных уравнениях и их применениях

В работе рассматривается идея применения аппарата дифференциальных уравнений в рамках глубокого обучения (нейронные обыкновенные дифференциальные уравнения или НОДУ) , а также предложена новая нейросетевая архитектура.
Предложенная модель p-ODE-RNN построена на вероятностном расширении реккурентной сети с предобработкой скрытого состояния нейронными дифференциальными уравнениями (ODE-RNN ). Сравнение нейросетевых архитектур и эксперименты по оценке их обощающей способности проводились на двух наборах данных: помесячная цена закрытия индекса Московской биржи и среднемесячная температура воздуха в городе Москве. Полученные результаты показывают, что p-ODE-RNN позволяет получать сопоставимое с ODE-RNN качество, затрачивая при этом значительно меньшее время на обучение. Также было показано, что можно рассматривать p-ODE-RNN как случайный процесс, что позволяет взглянуть на эту модель не только с точки зрения глубокого обучения.
Определение. Уравнение вида называется нейронным обыкновенным дифференциальным уравнением, в котором h — скрытое состояние сети, f — нейронная сеть, задающая динамику развития скрытого слоя, _ — её параметры, а t определяет нумерацию скрытых слоёв.
p-ODE-RNN. Рассмотрим новую архитектуру p-ODE-RNN, для которой скрытое состояние (слой сети) hi является случайной величиной следующего вида:
RNNCell( ) — блок стандартной реккурентной нейронной сети, ODESolve( ) — численный метод решения НОДУ. Параметр p был выбран равным 1. В качестве меры ошибки моделей был использован коэффициент детерминации или R2 = 1 SSres/SStot, где y  – вектор реальных значений, y – вектор, предсказанных значений