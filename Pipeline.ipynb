{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Библиотеки"
      ],
      "metadata": {
        "id": "o6B4vPbjYMJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import torchvision\n",
        "import random\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "\n",
        "try:\n",
        "    import transformers\n",
        "except ModuleNotFoundError:\n",
        "    !pip install transformers\n",
        "    !pip install transformers sentencepiece --quiet\n",
        "    clear_output()\n",
        "    import transformers\n",
        "from transformers import (\n",
        "    T5ForConditionalGeneration, T5TokenizerFast, T5Tokenizer,\n",
        "    DataCollatorForLanguageModeling, TrainingArguments, Trainer,\n",
        ")\n",
        "\n",
        "try:\n",
        "    import datasets\n",
        "except ModuleNotFoundError:\n",
        "    !pip install datasets\n",
        "    clear_output()\n",
        "from datasets import load_dataset\n",
        "\n",
        "try:\n",
        "    import rouge\n",
        "except ModuleNotFoundError:\n",
        "    ! pip install rouge\n",
        "    clear_output()\n",
        "from rouge import Rouge\n",
        "\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding\n",
        "\n",
        "try:\n",
        "    import nltk\n",
        "except ModuleNotFoundError:\n",
        "    ! pip install nltk\n",
        "    clear_output()\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "try:\n",
        "    import evaluate\n",
        "except ModuleNotFoundError:\n",
        "    ! pip install evaluate\n",
        "    ! pip install bert_score\n",
        "    clear_output()\n",
        "from evaluate import load"
      ],
      "metadata": {
        "id": "Dn-I2ukEm14l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Фиксируем сиды"
      ],
      "metadata": {
        "id": "cvdzdyuK2Rxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "#torch.use_deterministic_algorithms(True)"
      ],
      "metadata": {
        "id": "cputLBk81qB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пути для сохранения - измените и не забудьте подключить диск:"
      ],
      "metadata": {
        "id": "fslW36VoY2iM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYH9S3Dxmr8w"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/Colab Notebooks'\n",
        "saved_model_path = path + '/archive'\n",
        "checkpoint_path = path + '/t5-model-small'\n",
        "logs_path = checkpoint_path + '/logs'\n",
        "dataset_path = path + '/dataset'\n",
        "model_name = \"cointegrated/rut5-small\"\n",
        "pretrained_model = saved_model_path + '/model_t5_small_4.pth'\n",
        "test_path = path + '/texts'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Устройство ускорителя:"
      ],
      "metadata": {
        "id": "0Yxz6E1rY819"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "G4tD5mRzm6ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка"
      ],
      "metadata": {
        "id": "tp5o-IlbYQIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функции:"
      ],
      "metadata": {
        "id": "O4Qazx2rZAhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataset(data, tokenizer, max_length_text=2890, max_length_ref=200):\n",
        "    '''\n",
        "    Создать датасет для обучения модели: исходный текс обрабатывается токенизатором, а затем к полученному словарю добавляется метка label\n",
        "    с токенизированным эталонным рефератом\n",
        "\n",
        "    Возвращает преобразованный датасет (list)\n",
        "    '''\n",
        "    dataset = []\n",
        "    for inst in tqdm(data):\n",
        "        txt = tokenizer(inst['text'], add_special_tokens=True, max_length=max_length_text, padding=\"max_length\", truncation=True)\n",
        "        sum_ = tokenizer(inst['summary'], add_special_tokens=True, max_length=max_length_ref, padding=\"max_length\", truncation=True).input_ids\n",
        "        txt[\"labels\"] = sum_\n",
        "        dataset.append(txt)\n",
        "    return dataset\n",
        "\n",
        "def save(path, model, optimizer):\n",
        "    '''\n",
        "    Сохранить модель и оптимизатор в path\n",
        "    '''\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()\n",
        "    }, path)\n",
        "\n",
        "def summarize(text, model, tokenizer, max_length_text=2890, max_length_ref=500):\n",
        "    '''\n",
        "    Генерация реферата\n",
        "\n",
        "    Возвращает сгенерированный моделью реферат (str)\n",
        "    '''\n",
        "    inp = tokenizer(text, add_special_tokens=True, max_length=max_length_text, padding=\"max_length\", truncation=True, return_tensors='pt').to(device)\n",
        "    return tokenizer.decode(model.generate(input_ids=inp.input_ids, attention_mask=inp.attention_mask, max_length=max_length_ref)[0], skip_special_tokens=True)\n",
        "\n",
        "def tests_res(data, model, tokenizer, max_length_text=2890):\n",
        "    '''\n",
        "    Генерация рефератов для тестирования модели\n",
        "\n",
        "    Возвращает результат модели на датасете data (list) и эталонные рефераты (list)\n",
        "    '''\n",
        "    res, ref = [], []\n",
        "    for inst in tqdm(data):\n",
        "        res.append(summarize(inst['text'], model, tokenizer))\n",
        "        ref.append(inst['summary'])\n",
        "    return res, ref\n",
        "\n",
        "def read_dataset(model, tokenizer, max_length_text=2890, max_length_ref=200, n=50):\n",
        "    '''\n",
        "    Создать датасет для обучения (для чтения из директории)\n",
        "\n",
        "    Возвращает преобразованный датасет (list)\n",
        "    '''\n",
        "    dataset = []\n",
        "    for i in range(n):\n",
        "        with open(dataset_path + f'/{i}.txt') as f:\n",
        "            data = f.read()\n",
        "        data = data.split('\\n\\n')\n",
        "        txt = tokenizer(data[1], add_special_tokens=True, max_length=max_length_text, padding=\"max_length\", truncation=True)\n",
        "        sum_ = tokenizer(data[2], add_special_tokens=True, max_length=max_length_ref, padding=\"max_length\", truncation=True).input_ids\n",
        "        txt[\"labels\"] = sum_\n",
        "        dataset.append(txt)\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "t_dbfdwnm9mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка модели:"
      ],
      "metadata": {
        "id": "UvNFtuG2Yd4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка модели\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model_t5 = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "optimizer = torch.optim.AdamW(model_t5.parameters(),lr=1e-4)\n",
        "\n",
        "checkpoint = torch.load(pretrained_model, map_location='cpu')\n",
        "model_t5.load_state_dict(checkpoint['model_state_dict'])\n",
        "model_t5.to(device)\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
      ],
      "metadata": {
        "id": "e30TRPsMnWuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6617f64a-8de8-41eb-8db5-36e330b213c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type mt5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка датасета Gazeta и создание обучающей + валидационной выборок"
      ],
      "metadata": {
        "id": "UZ4YAHajYiIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка датасета\n",
        "dataset_train = load_dataset('IlyaGusev/gazeta', revision=\"v2.0\")[\"train\"]\n",
        "dataset_val = load_dataset('IlyaGusev/gazeta', revision=\"v2.0\")[\"validation\"]\n",
        "dataset_test = load_dataset('IlyaGusev/gazeta', revision=\"v2.0\")[\"test\"]\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "BEPjiu5goSac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание обучающей и валидационной выборок\n",
        "print('Making train dataset')\n",
        "dataset_train = make_dataset(dataset_train, tokenizer)\n",
        "print('Making val dataset')\n",
        "dataset_val = make_dataset(dataset_val, tokenizer)\n",
        "print('Done!')"
      ],
      "metadata": {
        "id": "6pLTQtKLafoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка метрик"
      ],
      "metadata": {
        "id": "7cOjdARaNDgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rouge = Rouge()\n",
        "meteor = load('meteor')\n",
        "bertscore = load(\"bertscore\")"
      ],
      "metadata": {
        "id": "WV1BOOkkNH1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "SkVScv9OYthb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если возникла ошибка, запустите код и перезапустите ноутбук:"
      ],
      "metadata": {
        "id": "ql_Yf06IYqp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "#if \"Using the `Trainer` with `PyTorch` requires `accelerate`: Run `pip install --upgrade accelerate`\" occured:\n",
        "! pip uninstall -y transformers accelerate\n",
        "! pip install transformers accelerate\n",
        "clear_output()\n",
        "# then reload notebook\n",
        "'''"
      ],
      "metadata": {
        "id": "Z4yYwwvE0dAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Дообучение на датасете Gazeta:"
      ],
      "metadata": {
        "id": "GebF-m6yAdXw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция для одного прогона обучение+текстирование (с логированием)"
      ],
      "metadata": {
        "id": "55sdO7n_CEU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_model(model, tokenizer, optimizer,\n",
        "                     test_dataset,\n",
        "                     num_steps=1, ):\n",
        "\n",
        "    for step in range(1, num_steps+1):\n",
        "        # параметры для Тренера\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir= checkpoint_path,\n",
        "            overwrite_output_dir=True,\n",
        "            per_device_train_batch_size=2,\n",
        "            per_device_eval_batch_size=2,\n",
        "            num_train_epochs=1,\n",
        "            warmup_steps=10,\n",
        "            gradient_accumulation_steps=16,\n",
        "            evaluation_strategy=\"epoch\",\n",
        "            save_strategy=\"epoch\",\n",
        "            load_best_model_at_end=True,\n",
        "            seed=42,\n",
        "        )\n",
        "\n",
        "        # Тренер\n",
        "        trainer = Trainer(\n",
        "            model=model_t5,\n",
        "            args=training_args,\n",
        "            train_dataset=dataset_train,\n",
        "            eval_dataset=dataset_val,\n",
        "            tokenizer=tokenizer,\n",
        "            optimizers = (optimizer, None)\n",
        "        )\n",
        "\n",
        "        # Обучение модели\n",
        "        model.train()\n",
        "        logs = trainer.train()\n",
        "        print('Saving model')\n",
        "        save(saved_model_path + f'/model_t5_small_5_{step}.pth', model, optimizer)\n",
        "\n",
        "        print('Saving loss')\n",
        "        with open(logs_path + f'/loss_dictionary.txt','a') as f:\n",
        "            f.write(f'Step_{step}\\nTRAIN LOG:\\n{logs}\\n')\n",
        "\n",
        "        # Тестирование модели\n",
        "        model.eval()\n",
        "        print('Testing')\n",
        "        model_results, refs = tests_res(test_dataset, model, tokenizer) # результаты работы модели\n",
        "\n",
        "        # Оценка ROUGE\n",
        "        print('Done! Counting Rouge')\n",
        "        scores = rouge.get_scores(model_results, refs, avg=True)\n",
        "        print(scores)\n",
        "\n",
        "        # Оценка BLEU\n",
        "        print('Done! Counting BLEU')\n",
        "        blue = corpus_bleu([[r.split(\" \")] for r in refs], [hyp.split(\" \") for hyp in model_results])\n",
        "        print(blue)\n",
        "\n",
        "        # Оценка METEOR\n",
        "        print('Done! Counting METEOR')\n",
        "        results_m = meteor.compute(predictions=model_results, references=refs)\n",
        "        print(results_m)\n",
        "\n",
        "        # Оценка BertScore\n",
        "        print('Done! Counting BertScore')\n",
        "        results_b = bertscore.compute(predictions=model_results, references=refs, lang=\"ru\")\n",
        "        results_b = {k: np.mean(v) for k, v in list(results_b.items())[:-1]}\n",
        "        print(results_b)\n",
        "\n",
        "        print('Saving scores')\n",
        "        with open(logs_path + f'/metrics.txt', 'a') as f:\n",
        "            f.write(f'STEP: {step}\\n')\n",
        "            f.write(f'ROUGE: {scores}\\n')\n",
        "            f.write(f'BLEU: {blue}\\n')\n",
        "            f.write(f'METEOR: {results_m}\\n')\n",
        "            f.write(f'BertScore: {results_b}\\n\\n')"
      ],
      "metadata": {
        "id": "0sbMm0pnCL1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_steps = 1\n",
        "\n",
        "train_test_model(model_t5, tokenizer, optimizer, dataset_test, num_steps=num_steps)"
      ],
      "metadata": {
        "id": "bAFZWJ4q-is4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Тестирование на своей выборке текстов:"
      ],
      "metadata": {
        "id": "8QuoeSZebJtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_t5.eval()"
      ],
      "metadata": {
        "id": "Rh5rd1BKIf-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(64):\n",
        "    t = open(test_path + f'/text_{i}', 'r', encoding='cp1251').read()\n",
        "    print(f'{i}) {summarize(t, model_t5, tokenizer)}')\n",
        "    print('-----------')"
      ],
      "metadata": {
        "id": "IIMUEcoPbRoB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97093439-dd75-404d-b36e-09dcfa281258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0) В работе рассматривается метод емкостной деионизации водного раствора, которые можно будет пропускать водного раствора через электрохимическую ячейку между двумя пористыми электродами. Это более энергоемкий метод опреснения воды в сравнении с методами обратного осмоса и дистилляции.\n",
            "-----------\n",
            "1) Для новых фактов и теорем можно будет использовать доказательные вычисления (ДВ) — вычисления, направленные на доказательство новых фактов и теорем и основанные на совместном применении численных и аналитических методов.\n",
            "-----------\n",
            "2) Для выделения гистологических изображений желез можно получить точные результаты для большого объема данных. Это было одним из основных критерий для успешного успешного успешного алгоритма сегментации гистологических изображений.\n",
            "-----------\n",
            "3) Методы подавления шума на изображениях можно будет работать в одном из основных задач в области обработки изображений. Это одна из основных задач в области обработки изображений.\n",
            "-----------\n",
            "4) Метод автоматического анализа минерального состава руд и вмещающих пород является важной задачей рудной геологии. Он используется в автоматизации разработки способов обогащения и в геолого-поисковых работах для выявления промышленного типа месторождения.\n",
            "-----------\n",
            "5) Метод анализа движения субклеточных структур на микроскопических изображениях для анализа движения субклеточных структур на микроскопических изображениях можно определить, что происходит в мышцах на молекулярном уровне. Для анализа их подвижности можно наблюдать с помощью микроскопа.\n",
            "-----------\n",
            "6) Для идентификации человека признаки, которые нужно выделить на изображении глаза необходимые для идентификации человека признаки, нужно выполнить сегментацию изображения. Для того, чтобы выделить на изображении глаза необходимые для идентификации признаки, нужно выполнить сегментацию изображения.\n",
            "-----------\n",
            "7) Метод граничных интегральных уравнений к задаче рассеяния электромагнитной волны на идеально проводящих телах можно представить через магнитные токи на поверхности тела. Для этого можно представить через магнитные токи на поверхности тела через так называемые эквивалентные магнитные токи на поверхности тела.\n",
            "-----------\n",
            "8) Метод шаблонов для выявления патологий в кровеносной системе может помочь при постановке диагноза и назначении дальнейшего лечения для пациента. Это может помочь при постановке диагноза и назначении дальнейшего лечения для пациента.\n",
            "-----------\n",
            "9) Ученые и разработчики новых технологий обнаружили предметы, расположенные за стеклом, а также при отражении инфракрасного отражения от пластика или стекла. Это представляет собой предмет будущих исследований.\n",
            "-----------\n",
            "10) Для совместения средств классического математического моделирования кровеносной системы можно диагностировать рассмотренную патологию кровотока по косвенным данным в сосудах, доступных для не инвазивного снятия параметров кровотока. Это может помочь совместить средства классического математического моделирования кровеносной системы.\n",
            "-----------\n",
            "11) Разрывный метод частиц для двумерного нелинейного переноса является ведущим методом для решения задач газодинамики. Это является ведущим методом для решения задач газодинамики.\n",
            "-----------\n",
            "12) Проблема восстановления табличных данных, заданных в виде вещественной двумерной матрицы, может быть проведена вариационным методом с учетом ошибок. Это может быть проведен методом, избегающим попадание в локальный экстремум.\n",
            "-----------\n",
            "13) Система автоматической сегментации зашумлённых речевых сигналов является одной из самых важных задач в области цифровой обработки речевых сигналов. Это дает возможность не только избавиться от ошибок, связанных с интерпретацией речевой активности, но и экономить на передаче данных по каналу связи.\n",
            "-----------\n",
            "14) Для конгруэнтности исходных комплексных матриц A и B можно проверить рационально. Это может быть проверено рационально, если они конгруэнтны. Если они конгруэнтны, то они конгруэнтны, то они конгруэнтны.\n",
            "-----------\n",
            "15) Методы идентификации динамических систем с возмущениями при помощи нейронных сетей и их алгоритмов. Это было одним из основных принципов для успешного идентификации динамических систем.\n",
            "-----------\n",
            "16) Для задач мониторинга функционирования длинных трубопроводов большое значение имеют средства, позволяющие по показаниям датчиков восстановить параметры течения жидкости во всем трубопроводе. Для задач мониторинга функционирования длинных трубопроводов большое значение имеют средства, позволяющие по показаниям датчиков восстановить параметры течения жидкости во всем трубопроводе.\n",
            "-----------\n",
            "17) Для управления и наблюдения для осциллирующей цепи можно восстановить данные о движении только одного из грузов цепи на фиксированном временном отрезке. Для этого можно восстановить данные о движении только одного из крайних грузов.\n",
            "-----------\n",
            "18) Рекуррентные уравнения для функции Беллмана в задаче суперхеджирования бинарных опционов с дискретным временем для европейского путопциона и европейского путопциона. Работа была проведена на серии публикаций, в которой развивается модель финансового рынка, связанная с детерминистическим подходом к эволюции цен с дискретным временем.\n",
            "-----------\n",
            "19) Работа посвящена исследованию мало изученной задачи управления колебаниями однородной прямоугольной мембраны с граничным управлением, соответствующим граничным условиям Дирихле. Работа посвящена исследованию мало изученной задачи управления колебаниями однородной прямоугольной мембраны с граничным управлением, соответствующим граничным условиям Дирихле.\n",
            "-----------\n",
            "20) Работа посвящена моделированию процессов управления движениями, происходящих в высших отделах головного мозга человека с целью определения численной оценки вклада в общую ошибку движения различных подсистем. Работа посвящена моделированию процессов управления движениями, происходящих в высших отделах головного мозга человека с целью определения численной оценки вклада в общую ошибку движения различных подсистем.\n",
            "-----------\n",
            "21) Разработка нейронных обыкновенных дифференциальных уравнений и их применения и их применения можно рассматривать как случайный процесс, что позволяет взглянуть на эту модель не только с точки зрения глубокого обучения.\n",
            "-----------\n",
            "22) Для обучения многослойных ансамблей можно будет работать на объектах из обучающей выборки. Это позволяет повысить обобщающую способность в сравнении с отдельными алгоритмами.\n",
            "-----------\n",
            "23) Для решения задач традиционного расстояния, параметризованных размеров, и их аппроксимация можно использовать более богатые множества функций. Для решения задач можно будет использовать более богатые множества функций, которые можно называть и для решения задач.\n",
            "-----------\n",
            "24) Для решения проблемы является вопрос синтеза, а также формирование алгоритмов поиска гамильтонова цикла в графе Кэли соответствующей группы. Это является основной задачей для поиска минимального пути в графе Кэли соответствующей группы.\n",
            "-----------\n",
            "25) Основополагающей задачей для исследования стала задача переноса стиля, которая представляет как практический, так и научный интерес. Это может стать причиной для решения самых разных задач.\n",
            "-----------\n",
            "26) Метод скелетизации бинарного изображения на основе плоского заметания является алгоритмом скелетизации бинарного изображения. Это является одним из ключевых терминов в анализе изображений.\n",
            "-----------\n",
            "27) Для сравнения учебных текстов, веб-сайтов, деловых и рекламных материалов можно будет использовать индексы удобочитаемости или когнитивной сложности текста. Это может быть использовано в образовательных платформах и поисково-рекомендательных системах, нацеленных на автоматизацию процесса изучения новых предметных областей пользователем.\n",
            "-----------\n",
            "28) Для умножителей можно было бы и можно было бы использовать в качестве базовых подсхем для умножения двух чисел. Для умножителей n m можно будет использовать в качестве базовых подсхем для построения более сложных схем.\n",
            "-----------\n",
            "29) Для источников неисправностей схемы можно рассматривать тесты относительно некоторых неисправностей входов схемы. Это может быть только один выход, если для любой СФЭ из множества схем можно рассматривать тесты для булевых функций.\n",
            "-----------\n",
            "30) Программа для расчета метаболических потоков с использованием 13C-углерода, которая может оказаться эффективной. Для этого можно будет самостоятельно определить, как именно распределился изотоп.\n",
            "-----------\n",
            "31) Схема групповой аутентификации пользователей приватных групповых конференций для обмена сообщениями в сети Интернет на основе доказательства с нулевым разглашением Разработана и разработана для разработки и исследования свойств алгоритма. Разработанный алгоритм позволяет выявить наличие цепочек групп в сети, связывающих пользователей, опираясь на существующие в сети цепочки групп.\n",
            "-----------\n",
            "32) Основная криптосистема HQC, построенная на основе квазициклических кодов Хэмминга, является кандидатом в стандарты. Это алгоритм, разработанный с использованием результатов теории кодирования, является кандидатом в стандарты.\n",
            "-----------\n",
            "33) Для того, как именно сетевой доступ к серверу, можно будет восстановить нажатия клавиш в SSH—сессии на уязвимом сервере, а не локальный и локальный и физический сервер. Это является наиболее трудоемким этапом проведения атаки по побочным каналам на кэши NetCAT.\n",
            "-----------\n",
            "34) Ученые считают, что в квантовой модели вычислений существуют эффективные алгоритмы решения сложных математических задач, которые можно отнести квантовые компьютеры. Это может стать задача для решения сложных математических задач, которые можно отнести квантовые компьютеры.\n",
            "-----------\n",
            "35) Технология AAA нового поколения позволяет увеличить функционал устройств системы «Интернет вещей». Для реализации новой парадигмы технологии AAA можно будет использовать различные объекты в медицинской сфере.\n",
            "-----------\n",
            "36) Создание тематических сообществ в социальных сетях может быть проведено на основе генерируемого контента. Это решение может быть проведено на основе латентно-семантического анализа документа-образца, а также на обучении нейросетевой модели на нетекстовых характеристиках участников сообщества.\n",
            "-----------\n",
            "37) Для облачных систем кодирования видеотрансляций видео можно будет работать объективная и полностью автоматическая оценка качества видео. Это очень важно для облачных систем кодирования, которые часто используются для сжатия, обработки, хранения и распространения видеоданных.\n",
            "-----------\n",
            "38) Проблема информационного поиска в социальных сетях — анализ сетевых сообществ, формирующих и распространяющих информацию экстремистского содержания, а также прогнозирование появления новых связей между участниками сообщества. В работе исследуются существующие и предлагаются собственные подходы для анализа сетевых сообществ, формирующих и распространяющих информацию экстремистского содержания.\n",
            "-----------\n",
            "39) Текстуры являются одной из основных компонентов синтеза реалистичных изображений в компьютерной графике. Это является одной из основных компонентов синтеза реалистичных изображений в компьютерной графике.\n",
            "-----------\n",
            "40) Для компьютерной диагностики в проекционной рентгенографии можно будет оказаться смертельными, если они обнаружены в своей поздней стадии. Это уже много лет существует дефицит высококвалифицированного медицинского персонала.\n",
            "-----------\n",
            "41) Для обучения астрономических объектов в рентгеновских обзорах неба необходимо отфильтровать звезды Млечного Пути, которые являются лучшими для исследования эволюции Вселенной. Для этого можно отфильтровать звезды Млечного Пути, которые являются лучшими для исследования эволюции Вселенной.\n",
            "-----------\n",
            "42) Программано-конфигурируемая сети в языке ассемблера сетевого процессора стала одним из самых популярных для них коммутатора. Для них можно будет смотреть таблицу потоков, а также смотреть правила в программе на языке ассемблера.\n",
            "-----------\n",
            "43) Для заданной конфигурации ВС и заданной задачи можно найти WCRT этой задачи. Для этой задачи можно найти новый метод решения задачи, которые можно будет называть аномальной для задачи B, если уменьшение времени выполнения задачи может привести к увеличению WCRT задачи.\n",
            "-----------\n",
            "44) Метод предотвращения атак распределённого отказа в обслуживании на контроллер в программно-конфигурируемых сетях является актуальной задачей, без решения которой внедрение технологий ПКС в реальных сетях невозможно.\n",
            "-----------\n",
            "45) Для анализа коммуникационных свойств параллельных программ можно было выделить коммуникационные матрицы, которые можно было выделить на них, а также найти изменения коммуникационных свойств параллельных приложений. Для анализа их анализа можно было выделить точные точки, соответствующие использованию коллективных операций в начале и в конце работы программы.\n",
            "-----------\n",
            "46) Для того, как можно обрабатывать большие объёмы данных, можно обрабатывать большие объёмы данных и производить колоссальное множество вычислений, а также их сложность. Это значит, что качество предсказаний и качество предсказаний является одной из показателей качества их программы.\n",
            "-----------\n",
            "47) Агент системы мониторинга производительности суперкомпьютера может проводить с помощью системы мониторинга производительности. Для того, чтобы не влиять на работающие задачи, агент может сделать лучшее, чем можно.\n",
            "-----------\n",
            "48) Разработчики процессорных датчиков, используемых для анализа производительности суперкомпьютерных приложений, помогают оценивать производительность выполнения программ. Для анализа производительности суперкомпьютерных приложений были изучены существующие работы по системе памяти процессоров семейства Haswell.\n",
            "-----------\n",
            "49) Для большинства людей это может быть простой задачей для визуального решения, а также для большинства людей это может быть простой задачей для визуального решения.\n",
            "-----------\n",
            "50) Компьютеры используются для работы с цифровыми данными, требующими творческого подхода, в частности с различными видами искусства. Это является одним из самых сложных направлений развития алгоритмов и алгоритмов работы с цифровыми данными.\n",
            "-----------\n",
            "51) Для того, как можно будет построить полноценную анкету, можно будет работать вручную. Для того, как для каждого вопроса будет определен раздел, то будет сформирован набор вопросов, которые являются основными и контрольными к нему вопросами.\n",
            "-----------\n",
            "52) Эксперты и эксперты разработали рекомендательный систему, основанной на знаниях юристов в области оспаривания штрафов за парковку в городе Москве и на знаниях, заключенных в нормативных актах, регулирующих данный вопрос. Эксперты считают, что штрафы можно выписать автоматически, а также избежать бессмысленного направления апелляций.\n",
            "-----------\n",
            "53) Ученые и разработчики синтаксического анализатора и синтаксического анализатора и его алгоритма для автоматической обработки текста и управления. Это одна из не полностью решенных задач в области автоматической обработки текста.\n",
            "-----------\n",
            "54) Решение полиномиального слагаемого из решений линейных дифференциальных уравнений с полиномиальными коэффициентами и правыми частями можно упростить уравнение. Это решение является искомое полиномиальное слагаемое решением уравнения.\n",
            "-----------\n",
            "55) Для распознавания шахматных позиций в режиме реального времени можно записывать ходы вручную или использовать дорогостоящие электронные доски. Для того, чтобы не обрабатывать каждый кадр из потока, то можно будет записывать ходы вручную или использовать дорогостоящие электронные доски.\n",
            "-----------\n",
            "56) Для построения компьютерного словаря русских паронимов можно будет понять только один из самых длинных слов, которые являются одним из корней и одной части речи, а также для повышения культуры речи. Для повышения культуры речи требуется полный словарь паронимов.\n",
            "-----------\n",
            "57) Работа нейронных сетей посвящена построению классификатора наводящих вопросов. Это может стать вопрос, заданный таким образом, чтобы получить определенный желаемый ответ.\n",
            "-----------\n",
            "58) Ученые ищет научные статьи в новой для него предметной области, а также ищет научные статьи в новой для него предметной области. Это является причиной высокой длительности и итеративности поиска, а также итеративности поиска.\n",
            "-----------\n",
            "59) Системные эмуляторы эмулируют всё аппаратное обеспечение и позволяют запускать ОС без внесения изменений. Это может помочь улучшению алгоритма доставки страничных нарушений в мониторе виртуальных машин.\n",
            "-----------\n",
            "60) Большинство существующих поисковых систем нацелено на удовлетворение отдельных, не связанных друг с другом поисковых запросов и не поддерживает длительный исследовательский поиск. Это решение было разработано в системе исследовательского поиска SciNoon, а также создание интерфейсов для работы с методом.\n",
            "-----------\n",
            "61) Для того, как именно аппаратный инструмент должен запускаться внутри аппарата виртуальной памяти, необходимо проверять, что нарушение возникает, когда должно возникать, и не возникает в иных случаях. Для того, чтобы проверить, что страничное нарушение возникает, когда должно возникать, и не возникает в иных случаях.\n",
            "-----------\n",
            "62) Автоматическое реферирование документов с учётом поискового запроса может помочь пользователю понять, стоит ли открывать документ целиком и продолжать его чтение более детально. Для этого можно понять, как можно будет делать это целиком и продолжать его чтение более детально.\n",
            "-----------\n",
            "63) Автоматизированное преобразование последовательных Си программ для распараллеливания программ применяется как ручное распараллеливание, характеризующееся наибольшей трудоёмкостью, так и полностью автоматическое распараллеливание, характеризующееся наибольшей трудоёмкостью, а также полностью автоматическое распараллеливание. Для этого можно выполнять только автоматическое распараллеливание, а также расширение скаляров.\n",
            "-----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Дообучение на своем датасете:"
      ],
      "metadata": {
        "id": "-Z4tIzDqZuTi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка датасета и создание выборки"
      ],
      "metadata": {
        "id": "wEJm5wnq8jPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = read_dataset(model_t5, tokenizer)\n",
        "\n",
        "test_set = []\n",
        "for i in range(50, 70):\n",
        "    with open(dataset_path + f'/{i}.txt') as f:\n",
        "        data = f.read()\n",
        "        data = data.split('\\n\\n')\n",
        "        test_set.append({'text': data[1], 'summary': data[2]})"
      ],
      "metadata": {
        "id": "I9_h05FBcyys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тренер:"
      ],
      "metadata": {
        "id": "utf5cR399qLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_t5.train()\n",
        "\n",
        "# параметры для Тренера\n",
        "training_args = TrainingArguments(\n",
        "    output_dir= checkpoint_path,\n",
        "    overwrite_output_dir=True,\n",
        "    per_device_train_batch_size=2,\n",
        "    num_train_epochs=1,\n",
        "    warmup_steps=10,\n",
        "    gradient_accumulation_steps=16,\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "# Тренер\n",
        "trainer = Trainer(\n",
        "    model=model_t5,\n",
        "    args=training_args,\n",
        "    train_dataset=train_set,\n",
        "    tokenizer=tokenizer,\n",
        "    optimizers = (optimizer, None)\n",
        ")"
      ],
      "metadata": {
        "id": "pgTk8urJcmRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучение + тестирование:"
      ],
      "metadata": {
        "id": "xIcJBtdAIV25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_steps = 1\n",
        "\n",
        "train_test_model(model_t5, tokenizer, optimizer, trainer, test_set, num_steps=num_steps)"
      ],
      "metadata": {
        "id": "Rn-QTEjkF615"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Тестирование на своей выборке текстов:"
      ],
      "metadata": {
        "id": "Gg8GqqKT9r8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_t5.eval()"
      ],
      "metadata": {
        "id": "oACSAwW0clOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(64):\n",
        "    t = open(test_path + f'/text_{i}', 'r', encoding='cp1251').read()\n",
        "    print(f'{i}) {summarize(t)}')\n",
        "    print('-----------')"
      ],
      "metadata": {
        "id": "0BfqriR29yyv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}