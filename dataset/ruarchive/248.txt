нас интересует следующая невыпуклая полуопределенная задача программирования: @xmath1, где @xmath2 выпукло, @xmath3 - непустое замкнутое выпуклое множество в @ xmath4, а @xmath5 ( @xmath6 ) - невыпуклые матричнозначные отображения и гладкие. обозначение @xmath7 означает, что @xmath8 является симметричной отрицательной полуопределенной матрицей. задачи оптимизации, включающие ограничения неравенства отображения с матричным значением, имеют большое количество применений при проектировании контроллера с обратной связью по статическому выходу и оптимизации топологии, см., например, @xcite. в частности, известно, что задачи оптимизации с ограничениями билинейного матричного неравенства (bmi) являются невыпуклыми и np - жесткими @xcite. было предпринято много попыток решить эти проблемы с помощью методов выпуклого полуопределенного программирования (в частности, оптимизации с ограничениями линейного матричного неравенства (lmi)) @xcite. методы, разработанные в этих статьях, основаны на расширенных функциях лагранжа, обобщенном последовательном полуопределенном программировании и чередующихся направлениях. недавно мы предложили новый метод, основанный на выпукло- вогнутой декомпозиции ограничений bmi и технике линеаризации @xcite. метод использует выпуклую подструктуру задач. было показано, что этот метод может быть применен для решения многих задач, возникающих при статическом управлении с обратной связью на выходе, включая задачи синтеза спектральной абсциссы, @xmath9, @xmath10 и смешанной @xmath11.    в этой статье мы следуем тому же направлению работы в @xcite, чтобы разработать новый метод локальной оптимизации для решения невыпуклой задачи полуопределенного программирования. основная идея заключается в аппроксимации допустимого множества невыпуклой задачи последовательностью внутренних положительных полуопределенных выпуклых аппроксимационных множеств. этот метод можно рассматривать как обобщение методов, описанных в @xcite. 0.1 cm _ вклад. _ вклад этой статьи можно резюмировать следующим образом: * мы обобщаем метод внутренней выпуклой аппроксимации в @ xcite от скалярной оптимизации до нелинейного полуопределенного программирования. более того, алгоритм модифицирован с использованием _ метода регуляризации _ для обеспечения строгого спуска. преимущества этого алгоритма заключаются в том, что он _ очень прост в реализации _ за счет использования доступных стандартных программных средств полуопределенного программирования и _ не требует стратегии глобализации _, такой как процедура линейного поиска. * мы доказываем сходимость алгоритма к стационарной точке в мягких условиях. * мы предлагаем два конкретных способа формирования завышенной оценки для билинейных матричных отображений, а затем показываем множество приложений в статической обратной связи на выходе.    0,1 см _ контур. _ в следующем разделе приводятся некоторые определения, обозначения и свойства матричных операторов и определяется внутренняя выпуклая аппроксимация ограничения bmi. раздел [ sec : alg_and_conv ] предлагает основной алгоритм и исследует его свойства сходимости. в разделе [ sec : app ] показаны приложения для статического управления с обратной связью на выходе и численных тестов. некоторые заключительные замечания приведены в последнем разделе. в этом разделе, после обзора концепций и определений, связанных с матричными операторами, мы приводим определение внутренней положительной полуопределенной выпуклой аппроксимации невыпуклого множества. пусть @xmath12 - набор симметричных матриц размера @xmath13, @xmath14 и соответственно, @xmath15 - набор симметричных положительных полуопределенных, соответственно, положительно определенных матриц. для заданных матриц @xmath16 и @xmath17 в @xmath12 отношение @xmath18 ( соответственно, @xmath19 ) означает, что @xmath20 ( соответственно, @xmath21 ) и @xmath22 ( соответственно, @xmath23 ) равно @xmath24 ( соответственно, @xmath25 ). величина @xmath26 является внутренним произведением двух матриц @xmath16 и @xmath17, определенных в @xmath12, где @xmath27 - это след матрицы @xmath28. для данной симметричной матрицы @xmath16, @xmath29 обозначает наименьшее собственное значение @xmath16. [ de : psd_convex]@xcite матричное отображение @xmath30 называется положительным полуопределенно выпуклым ( _ psd - convex _ ) на выпуклом подмножестве @xmath31, если для всех @xmath32 $ ] и @xmath33 имеется @xmath34, если выполняется для @xmath35 вместо @xmath36 для @xmath37, тогда @xmath38 считается _ строго psd - выпуклым _ в @xmath39. в противоположном случае @xmath38 называется _ psd - невыпуклым. в качестве альтернативы, если мы заменим @xmath36 на @xmath40, то @xmath38 будет считаться psd - вогнутым на @xmath39. очевидно, что любая выпуклая функция @xmath2 является psd - выпуклой с помощью @xmath41. функция @xmath42 называется _ сильно выпуклой _ с параметром @xmath43, если @xmath44 выпуклая. обозначение @xmath45 обозначает субдифференциал выпуклой функции @xmath46. для данного выпуклого множества @xmath39, @xmath47, если @xmath48, и @xmath49, если @xmath50 обозначает нормальный конус @xmath39 в @xmath51. производная матричного отображения @ xmath38 в @ xmath51 является линейным отображением @ xmath52 от @ xmath4 до @ xmath53, которое определено @xmath54 для данного выпуклого множества @xmath55, матричное отображение @xmath56 называется дифференцируемым на подмножестве @xmath16, если его производная @xmath57 существует в каждом @xmath58. определения производных второго порядка матричнозначных отображений можно найти, например, в @xcite. пусть @xmath59 - линейное отображение, определенное как @xmath60, где @xmath61 для @xmath62. сопряженный оператор @xmath8, @xmath63, определяется как @xmath64 для любого @xmath65. наконец, для простоты обсуждения на протяжении всей этой статьи мы предполагаем, что все функции и матричнозначные отображения _ дважды дифференцируемы _ в своей области. давайте сначала опишем идею внутренней выпуклой аппроксимации для скалярного случая. пусть @xmath42 - непрерывная невыпуклая функция. выпуклая функция @xmath66, зависящая от параметра @xmath67, называется выпуклым завышением @xmath68 по сравнению с параметризацией @xmath69, если @xmath70 и @xmath71 для всех @xmath72. давайте рассмотрим два примера. 0,1 см _ пример 1. _ пусть @xmath46 - непрерывно дифференцируемая функция, а ее градиент @xmath73 непрерывен по Липшицу с постоянной Липшица @xmath74, т.е. @xmath75 для всех @xmath76. тогда хорошо известно, что @xmath77. следовательно, для любого @xmath78 у нас есть @xmath79 с @xmath80. более того, @xmath81 для любого @xmath51. мы приходим к выводу, что @xmath82 является выпуклым завышением @xmath46 по сравнению с параметризацией @xmath83. теперь, если мы исправим @xmath84 и найдем точку @xmath85 такую, что @xmath86, то @xmath87. следовательно, если множество @xmath88 непусто, мы можем найти точку @xmath85 такую, что @xmath86. выпуклое множество @xmath89 называется внутренним выпуклым приближением @xmath90.    0,1 см _ пример 2. _ @xcite мы рассматриваем функцию @xmath91 в @xmath92. функция @xmath93 является выпуклым завышением @xmath46 по сравнению с параметризацией @xmath94 при условии, что @xmath95. этот пример показывает, что отображение @xmath96 не всегда является тождественным. давайте обобщим концепцию выпуклого завышения на матричнозначные отображения. [ def : over_relaxation ] давайте рассмотрим отображение psd - невыпуклой матрицы @xmath97. говорят, что psd - выпуклое матричное отображение @xmath98 является psd - выпуклым завышением @xmath38 по сравнению с параметризацией @xmath69, если @xmath99 и @xmath100 для всех @xmath76 и @xmath101 в @xmath102.    давайте приведем два важных примера, которые удовлетворяют определению [ def : over_relaxation ].    _ пример 3. _ пусть @xmath103 - билинейная форма с @xmath104, @xmath105 и @xmath106 произвольно, где @xmath16 и @xmath17 - две матрицы @xmath107. мы рассматриваем параметрическую квадратичную форму : @xmath108 можно показать, что @xmath109 является psd - выпуклым завышением @xmath110 по сравнению с параметризацией @xmath111.    действительно, очевидно, что @xmath112. мы доказываем только второе условие в определении [ def : over_relaxation ]. мы рассматриваем выражение @xmath113. переставив это выражение, мы можем легко показать, что @xmath114. теперь, поскольку @xmath104, с помощью @xcite мы можем написать: @xmath115 обратите внимание, что @xmath116. следовательно, у нас есть @xmath117 для всех @xmath118 и @xmath119. _ пример 4. _ давайте рассмотрим psd - невыпуклое матричное отображение @xmath120, где @xmath121 и @xmath122 - это два psd - выпуклых матричных отображения @xcite. теперь пусть @xmath122 является дифференцируемым, а @xmath123 - линеаризацией @xmath122 в @xmath124. мы определяем @xmath125. нетрудно показать, что @xmath126 является psd - выпуклым завышением @xmath127 по сравнению с параметризацией @xmath128. [ re : nonunique_of_bmi_app ] _ пример 3 _ показывает, что `коэффициент Липшица\" аппроксимирующей функции равен @xmath129. более того, как указано в _ примерах _ 3 и 4, завышение psd - выпуклости билинейной формы не является уникальным. на практике важно найти подходящие psd - выпуклые завышения для билинейных форм, чтобы алгоритм работал эффективно. обратите внимание, что psd - выпуклое завышение @xmath130 из @xmath131 в _ примере 3 _ может быть менее консервативным, чем выпукло - вогнутое разложение в @xcite, поскольку все термины в @xmath130 связаны с @xmath132 и @xmath133, а не с @xmath16 и @xmath17. давайте вспомним невыпуклую задачу полуопределенного программирования. мы обозначаем через @xmath134 допустимый набор и @xmath135 относительную внутреннюю часть @xmath136, где @xmath137 - относительная внутренняя часть @xmath3. во-первых, нам нужно следующее фундаментальное предположение.    [ as : a1 ] множество внутренних точек @xmath138 из @xmath136 непусто. затем мы можем записать обобщенную систему kkt следующим образом: @xmath139 любая точка @xmath140 с @xmath141 называется точкой _ kkt_ of, где @xmath142 называется _ стационарной точкой _, а @xmath143 называется соответствующим множителем Лагранжа. основным шагом алгоритма является решение выпуклой задачи полуопределенного программирования, сформированной на итерации @xmath144, с использованием внутренних psd - выпуклых аппроксимаций. эта проблема определяется следующим образом: @xmath145 здесь указан @xmath146, а второй член целевой функции упоминается как член регуляризации; @xmath147 - это параметризация выпуклого завышения @xmath148 из @xmath149. leдавайте определим с помощью @xmath150 отображение решения [ eq : convx_subprob ] в зависимости от параметров @xmath151. Обратите внимание, что задача [ eq : convx_subprob ] является выпуклой, @xmath152 многозначна и выпукла. допустимый набор [ eq : convx_subprob ] записывается как : @xmath153 алгоритм решения начинается с начальной точки @xmath154 и генерирует последовательность @xmath155 путем решения последовательности выпуклых полуопределенных подзадач программирования [ eq : convx_subprob ], аппроксимированных в @xmath156. точнее, он подробно представлен как следует. [ alg : a1 ] * инициализация. * определите начальную точку @xmath157. вычислите @xmath158 для @xmath6. выберите матрицу регуляризации @xmath159. установите @xmath160. * итерация @xmath161 ( @xmath162 ) * выполните следующие шаги: * _ шаг 1. _ для заданного @xmath156, если заданный критерий удовлетворен, завершите. * _ решите выпуклую полуопределенную программу [ eq : convx_subprob ], чтобы получить решение @xmath163 и соответствующий множитель Лагранжа @xmath164. * _ обновите @xmath165, матрицу регуляризации @xmath166 (при необходимости). увеличьте @xmath161 на @xmath167 и вернитесь к шагу 1.    * * основным шагом алгоритма [ alg : a1 ] является шаг 2, на котором необходимо решить общую выпуклую полуопределенную программу. на практике это может быть сделано либо путем реализации определенного метода, использующего проблемные структуры, либо с помощью стандартных программных средств полуопределенного программирования. обратите внимание, что матрица регуляризации @xmath168 может быть зафиксирована в @xmath169, где @xmath43 достаточно мала, а @xmath170 является единичной матрицей. поскольку алгоритм [ alg : a1 ] генерирует допустимую последовательность @xmath155 для исходной задачи, и эта последовательность является строго нисходящей по отношению к целевой функции @xmath46, _ никакая стратегия глобализации _, такая как поиск по строке или регион доверия, не требуется. сначала мы покажем некоторые свойства допустимого множества @xmath171, определенного с помощью. для простоты записи мы используем обозначение @xmath172.    [ le : feasible_set ] пусть @xmath173 - последовательность, сгенерированная алгоритмом [ alg : a1 ]. затем : * @xmath174 допустимый набор @xmath175 для всех @xmath176. * @xmath177 это допустимая последовательность, т.е. @xmath178. * @xmath179 @xmath180. * @xmath181 для любого @xmath182 это означает, что : @xmath183, где @xmath184 - параметр сильной выпуклости @xmath46.    для данного @xmath156 у нас есть @xmath185 и @xmath186 для @xmath6. таким образом, если @xmath187, то @xmath188, утверждение a ) выполняется. следовательно, последовательность @xmath189 выполнима, что действительно является утверждением b ). поскольку @xmath163 является решением [ eq : convx_subprob ], это показывает, что @xmath190. теперь мы должны показать, что он принадлежит @xmath191. действительно, поскольку @xmath192 по определению [ def : over_relaxation ] для всех @xmath6, мы заключаем @xmath193. утверждение c ) доказано. наконец, мы докажем d ). поскольку @xmath163 является оптимальным решением [ eq : convx_subprob ], у нас есть @xmath194 для всех @xmath187. однако мы имеем @xmath195 из-за c ). подставляя @xmath196 в предыдущее неравенство, мы получаем оценку d ). теперь мы обозначим через @xmath197 набор нижнего уровня целевой функции. давайте предположим, что @xmath198 непрерывно дифференцируем в @xmath199 для любого @xmath67. мы говорим, что условие _ robinson qualification _ для [ eq : convx_subprob ] выполняется при @xmath124, если @xmath200 для @xmath6. чтобы доказать сходимость алгоритма [ alg : a1 ], нам требуется следующее предположение.    [ as : a2 ] множество точек kkt из непусто. для данного @xmath67 матричные отображения @xmath198 непрерывно дифференцируемы на @xmath199. выпуклая задача [ eq : convx_subprob ] разрешима, и квалификационное условие Робинсона выполняется при ее решениях. заметим, что если алгоритм 1 завершается на итерации @xmath161 таким образом, что @xmath201, то @xmath156 является стационарной точкой. [ th : сходимость ] предположим, что предположения a.[as : a1 ] и a.[as : a2 ] выполнены. предположим далее, что набор нижнего уровня @xmath199 ограничен. пусть @xmath202 - бесконечная последовательность, сгенерированная алгоритмом [ alg : a1 ], начиная с @xmath157. предположим, что @xmath203. тогда, если либо @ xmath46 сильно выпуклый, либо @xmath204 для @ xmath182, то каждая точка накопления @xmath205 из @ xmath206 является точкой kkt из. более того, если множество точек kkt из конечно, тогда вся последовательность @xmath207 сходится к точке kkt из. Во-первых, мы покажем, что точка отображение решения @xmath150 _ закрыто_. действительно, в предположении a.[as : a2 ], [ eq : convx_subprob ] выполнимо. более того, оно сильно выпуклое. следовательно, @xmath208, который, очевидно, закрыт. остальные выводы теоремы могут быть доказаны аналогично (* ? ? ? * теорема 3.2.), используя теорему о сходимости Зангвилла, подробности которой мы здесь опускаем. [ rm: выводы ] обратите внимание, что предположения, используемые при доказательстве замкнутости отображения решения @xmath209 в теореме [ th: сходимость], слабее, чем те, которые используются в (* ? ? ? * теорема 3.2.). в этом разделе мы представляем некоторые приложения алгоритма [ alg : a1 ] для решения нескольких классов оптимизационных задач, возникающих при проектировании контроллера со статической выходной обратной связью. как правило, эти проблемы связаны со следующей линейной, не зависящей от времени (lti) системой вида: @xmath210, где @xmath211 - вектор состояния, @xmath212 - входные данные производительности, @xmath213 - входной вектор, @xmath214 - выходные данные производительности, @xmath215 - физический выходной вектор, @xmath216 - матрица состояний, @xmath217 - входная матрица и @xmath218 - выходная матрица. используя контроллер статической обратной связи вида @xmath219 с @xmath220, мы можем записать замкнутую систему следующим образом: @xmath221 стабилизация, @xmath9, @xmath222 оптимизация и другие задачи управления системой lti могут быть сформулированы как задача оптимизации с ограничениями bmi. мы используем только psd - выпуклое завышение билинейной формы в _ примере 3 _, чтобы показать, что алгоритм [ alg : a1 ] может быть применен для решения многих проблем при проектировании контроллера с обратной связью по статическому состоянию/выходу, таких как: * разреженный линейный контроллер с обратной связью по статическому выходу; * оптимизация спектральной абсциссы и псевдоспектральной абсциссы ; * оптимизация @xmath223 ; * оптимизация @xmath224 ; * и смешанный синтез @xmath225. эти задачи обладают, по крайней мере, одним ограничением bmi из @xmath226, где @xmath227, где @xmath118 и @xmath28 являются матричными переменными, а @xmath228 является аффинным оператором матричной переменной @xmath28. с помощью _ примера 3 _ мы можем аппроксимировать билинейный член @xmath229 его psd - выпукло переоценивать. затем, используя дополнение Шура, преобразуем ограничение @xmath230 подзадачи [ eq : convx_subprob ] в ограничение lmi @xcite. обратите внимание, что алгоритм [ alg : a1 ] требует внутренней начальной точки @xmath231. в этой работе мы применяем процедуры, предложенные в @xcite, чтобы найти такую точку. теперь мы резюмируем всю процедуру, применяемую для решения задач оптимизации с ограничениями bmi, следующим образом: [ схема : a1 ] + _ шаг 1. _ найдите psd - выпуклое завышение @xmath232 из @xmath233 с параметризацией @xmath234 для @xmath235 (см. _ пример 1 _ ). + _ шаг 2. _ найдите отправную точку @xmath157 ( смотрите @xcite ). + _ шаг 3. _ для заданного @xmath156 сформулируйте задачу выпуклого полуопределенного программирования [ eq : convx_subprob ] и переформулируйте ее как оптимизацию с ограничениями lmi. + _ шаг 4. _ примените алгоритм [ alg : a1 ] с sdp-решателем для решения данной задачи. теперь мы тестируем алгоритм [ alg : a1 ] для трех задач на численных примерах, используя данные из библиотеки comp@xmath236ib @xcite. все реализации выполнены в matlab 7.8.0 (r2009a), работающем на ноутбуке Intel(r) core(tm)i7 q740 с тактовой частотой 1,73 ГГц и 4 гб оперативной памяти. мы используем пакет yalmip @xcite в качестве языка моделирования и sedumi 1.1 в качестве sdp-решателя @xcite для решения задач оптимизации lmi, возникающих в алгоритме [ alg : a1 ] на начальной фазе (фаза 1 ) и подзадаче [ eq : convx_subprob ]. код доступен по адресу http://www.kuleuven.be/optec/software/bmisolver. мы также сравниваем производительность алгоритма [ alg : a1 ] и метода выпукло- вогнутой декомпозиции (ccdm), предложенного в @xcite в первом примере, т.е. задачи оптимизации по спектральной абсциссе. во втором примере мы сравниваем норму @xmath10, вычисленную алгоритмом [ alg : a1 ], и норму, предоставленную hifoo @xcite и penbmi @xcite. последним примером является задача оптимизации смешанного синтеза @xmath237, в которой мы сравниваем два значения уровня нормы @xmath238. мы рассматриваем задачу оптимизации с ограничением имт путем оптимизации спектральной абсциссы замкнутой системы @xmath239 как @xcite : @xmath240 здесь приведены матрицы @xmath216, @xmath217 и @xmath218. матрицы @xmath241 и @xmath220 и скаляр @xmath242 рассматриваются как переменные. если оптимальное значение строго положительное, то контроллер обратной связи с замкнутым контуром @xmath219 стабилизирует линейную систему @xmath243.    введя промежуточную переменную @xmath244, ограничение bmi во второй строке может быть записано как @xmath245. теперь, применив схему [ scheme : a1 ], можно решить проблему, используя sedumi sdp solver @xcite. чтобы получить строго заданное направление спуска, мы упорядочиваем подзадачу [ eq : convx_subprob ], добавляя квадратичные члены: @xmath246, где @xmath247. алгоритм [ alg : a1 ] завершается, если выполняется одно из следующих условий: * подзадача [ eq : convx_subprob ] сталкивается с числовой проблемой; * @xmath248; * достигнуто максимальное количество итераций, @xmath249; * или целевая функция не улучшается значительно после двух последовательных итерации, т.е. @xmath250 для некоторых @xmath251 и @xmath252, где @xmath253. мы тестируем алгоритм [ alg : a1 ] для нескольких задач в comp@xmath236ib и сравниваем наши результаты с результатами, полученными методом выпукло - вогнутой декомпозиции (ccdm) в @xcite.    -0,45 см.вычислительное разрешениеults для in comp@xmath254ib [ cols= \" \u003c, \u003e, \u003e, \u003e, \u003e, \u003e, \u003e, \u003e, \u003e, \u003e \", ] здесь @xmath225 - это нормы @xmath223 и @xmath224 для систем с замкнутым контуром для контроллера со статической выходной обратной связью, соответственно. с помощью @xmath255 результаты вычислений показывают, что алгоритм [ alg : a1 ] удовлетворяет условию @xmath256 для всех тестовых задач. задачи ac11 и ac12 сталкиваются с численными задачами, которые алгоритм [ alg : a1 ] не может решить. в то время как в случае с @xmath257 сообщается о невыполнимых проблемах @xmath258, которые обозначаются знаком ` - \". Ограничение @xmath224 для трех проблем ac11 и nn8 активно по отношению к @xmath257. мы предложили новую итерационную процедуру для решения класса невыпуклых задач полуопределенного программирования. ключевая идея заключается в локальной аппроксимации невыпуклого допустимого множества задачи внутренним выпуклым множеством. сходимость алгоритма к стационарной точке исследуется при стандартных предположениях. мы ограничиваем наши приложения задачами оптимизации с ограничениями bmi и предоставляем конкретный способ вычисления внутренней psd - выпуклой аппроксимации ограничения bmi. было показано множество применений при проектировании контроллера с обратной связью по статическому выходу и представлены два численных примера. обратите внимание, что этот метод может быть расширен для решения более общих невыпуклых задач sdp, где нам удается найти внутреннюю psd - выпуклую аппроксимацию допустимого множества. это также наше будущее направление исследований.

в этой работе мы предлагаем новый метод локальной оптимизации для решения класса невыпуклых задач полуопределенного программирования (sdp). основная идея заключается в аппроксимации допустимого множества невыпуклой задачи sdp внутренними положительными полуопределенными выпуклыми аппроксимациями с помощью метода параметризации. это приводит к итеративной процедуре поиска локального оптимума невыпуклой задачи. сходимость алгоритма анализируется при умеренных допущениях. приложения для статического управления с обратной связью на выходе сравниваются и выполняются численные тесты на основе данных из библиотеки compl@xmath0ib.