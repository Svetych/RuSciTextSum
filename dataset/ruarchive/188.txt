в физике высоких энергий (hep) разворачивание (также называемое размазыванием) - это общий термин, описывающий методы, которые пытаются устранить эффект размытия разрешения, чтобы получить измерение истинного базового распределения величины. обычно полученные данные (искаженные реакцией детектора, неэффективностью и т.д.) объединяются в гистограмму. результатом некоторой процедуры развертывания является новая гистограмма с оценками истинного среднего содержимого ячейки до размытия и неэффективности, а также некоторых связанных с этим неопределенностей. обычно предполагается, что такие развернутые распределения полезны с научной точки зрения для сравнения данных с одним или несколькими теоретическими предсказаниями или даже в качестве количественных измерений, которые будут использованы в дальнейших расчетах. поскольку важным аспектом научного предприятия является проверка гипотез, мы можем спросить: `следует ли использовать развернутые гистограммы для проверки гипотез? \" если ответ утвердительный, то можно далее спросить, существуют ли ограничения на полезность проверки гипотез с использованием развернутых гистограмм. если ответ отрицательный, то обоснование для развертывания, по-видимому, ограничено. в этой заметке мы иллюстрируем подход к ответу на заглавный вопрос несколькими вариациями на примере игрушки, который отражает некоторые особенности реальных задач развертывания в hep. цель заметки - пробудить больший интерес к изучению того, что один из нас (rc) назвал \"итоговым тестом\" для метода развертывания: _ если развернутый спектр и предоставленные неопределенности будут полезны для оценки того, какой из двух моделей благоприятствуют данные (и каким образом много ), то ответ должен быть существенно таким же, как тот, который получается путем размытия двух моделей и непосредственного сравнения с данными без развертывания _ это другой акцент при оценке методов развертывания, чем в исследованиях, которые фокусируются на промежуточных величинах, таких как смещение и дисперсия оценок истинного среднего содержание, а также о частотном охвате соответствующих доверительных интервалов. хотя основное внимание здесь уделяется сравнению двух моделей на предмет определенности, основная идея, конечно, применима к сравнению одной модели с данными (т.е. к степени соответствия) и к более общим тестам гипотез. недавно zech @ xcite расширил понятие итогового теста на оценку параметров от соответствия развернутым данным и выявил сбои в изученных случаях, особенно в отношении соответствия ширине пика. мы используем обозначение монографии \"статистический анализ данных\" Глена Коуэна @xcite (для простоты исключая фоновый вклад, который он называет @xmath0): @xmath1 - это непрерывная переменная, представляющая _ истинное _ значение некоторой величины, представляющей физический интерес (например, импульса). он распределяется в соответствии с pdf @xmath2. @xmath3 - непрерывная переменная, представляющая наблюдаемое значение той же величины, представляющей физический интерес, после эффектов размытия детектора и потери событий (если таковые имеются) из-за неэффективности. @xmath4 - это функция разрешения детектора: условный pdf для наблюдения @xmath3, учитывая, что истинное значение равно @xmath1 (и учитывая, что оно где-то наблюдалось). @xmath5 содержит ожидаемые значения содержимого ячейки гистограммы _ true _ (несмазанной) из @xmath1 ; @xmath6 содержит содержимое ячейки гистограммы _ observed _ (называемой _ размазанной гистограммой _ или иногда _ свернутой _ гистограммой) из @xmath3 в одном файле. эксперимент ; @xmath7 содержит ожидаемые значения содержимого ячейки _ наблюдаемой _ (размытой) гистограммы @xmath3, включая эффект неэффективности : @xmath8 $ ] ; @xmath9 - матрица ответов, которая дает вероятность того, что событие в истинной ячейке @xmath10 будет наблюдаться в ячейке @xmath11 после размазывания : @xmath12 ; @xmath13 содержит точечные оценки @xmath14, которые являются результатом алгоритма развертывания. @xmath15 - это ковариационная матрица оценок @xmath16 : @xmath17 $ ]. оценка @xmath15, предоставляемая алгоритмом развертывания, равна @xmath18. таким образом, мы имеем @xmath19 как обсуждалось Коуэном и отмечалось выше, @xmath9 включает в себя эффект эффективности @xmath20, т.е. эффект событий на истинных гистограммах, которые не наблюдаются на размытой гистограмме. единственный эффект эффективности, который мы здесь рассматриваем, заключается в том, что события размазываются за пределами границ гистограммы. (то есть мы не рассматриваем ячейку с недостаточным потоком или ячейку с переполнением. ) матрица отклика @xmath9 зависит от функции разрешения и от (неизвестного) истинного содержимого ячейки (и, в частности, от их истинной плотности @xmath2 _ внутри _ каждой ячейки), и, следовательно, @xmath9 либо известен только приблизительно, либо как функция предположений об истинном содержимом ячейки. номера ячеек @xmath21 и @xmath22 необязательно должны совпадать. ( часто предлагается использовать @xmath23, в то время как @xmath24 оставляет систему уравнений недоопределенной. ) для обсуждаемых здесь исследований игрушек мы устанавливаем @xmath25, так что @xmath9 - это квадратная матрица, которая обычно имеет обратную.    в размытом пространстве мы принимаем наблюдаемые значения @xmath26 за независимые наблюдения из базовых распределений Пуассона: @xmath27 затем разворачивающаяся проблема заключается в использовании @xmath9 и @xmath26 в качестве входных данных для получения оценок @xmath16 из @xmath14 и для получения ковариационной матрицы @xmath15 этих оценок (или скорее оценка @xmath15, @xmath18 ), в идеале учитывающая неопределенность в @xmath9. сообщая о развернутых результатах, авторы сообщают @xmath16, в идеале вместе с @xmath18. (если отображается только гистограмма @xmath16 с `полосами ошибок\", то передаются только диагональные элементы @xmath18, что еще больше ухудшает качество информации. ) `итоговый тест\" применения unfolding заключается в том, могут ли тесты гипотез о базовых моделях, которые предсказывают @xmath14, получить значимые результаты, если они принимают в качестве входных данных @xmath16 и @xmath18. для нулевой гипотезы @xmath28 мы считаем, что непрерывная переменная @xmath1 распределяется в соответствии с истинным pdf @xmath29, где @xmath30 известен, а @xmath31 - константа нормализации. для альтернативной гипотезы @xmath32 мы считаем, что @xmath1 распространяется в соответствии с истинным pdf @xmath33, где @xmath30 - это то же самое, что и в нулевой гипотезе, и где @xmath34 - это pdf, который кодирует отклонение от нулевой гипотезы. в этой заметке мы предполагаем, что как @xmath34, так и @xmath35 известны и приводят к потенциально значительным отклонениям от нулевой гипотезы в целом @xmath1. константа @xmath35 контролирует уровень таких отклонений. на рисунке [ truepdfs ] показаны базовые PDF-файлы, которые составляют основу текущего исследования, для которого мы принимаем @xmath36 за нормализованное гамма-распределение, @xmath37 и @xmath38. представлен символом @xmath39, выделенным красным цветом. альтернативная гипотеза @xmath32 имеет дополнительный компонент, показанный синим пунктиром, с суммой @xmath40 сплошным синим цветом., title=\"fig:\",scaledwidth=49,0% ] представлен @xmath39, показанным красным. альтернативная гипотеза @xmath32 имеет дополнительный компонент, показанный пунктирным синим цветом, с суммой @xmath40 сплошным синим цветом., title=\"fig:\",scaledwidth=49,0% ] для каждой гипотезы истинное содержимое ячейки @xmath14 затем пропорционально интегралу от соответствующего @xmath2 по каждому мусорное ведро. для обеих гипотез мы принимаем размытие @xmath3 за функцию разрешения по Гауссу, @xmath41, где известно значение @xmath42.    для построения базовых графиков мы используем значения, приведенные в таблице [базовая линия ], и изучаем влияние изменения одного параметра за раз. как для @xmath3, так и для @xmath1 мы рассматриваем гистограммы с 10 ячейками шириной 1, охватывающими интервал [ 0,10 ]. Значение по умолчанию @xmath42 равно половине ширины этой ячейки. величины @xmath14, @xmath9 и @xmath43 затем легко вычисляются, как показано в ссылке. на рисунке [ histos ] отображаются @xmath14 и @xmath43 (сплошными гистограммами ), в то время как на рис. [ responsepurity ] отображает матрицу ответов, а также исходную ячейку событий, которые наблюдаются в каждой ячейке. в каждом моделируемом эксперименте общее количество событий выбирается из распределения Пуассона со средним значением, указанным в таблице [ базовый уровень ]..значения параметров, используемых в примерах развертывания базового уровня [ cols=\"\u003c,\u003c,\u003c\",options=\"header\", ] и размазаны @xmath43, для ( слева ) нулевая гипотеза @xmath28 и (справа ) альтернативная гипотеза @xmath32. точки данных: в моделировании mc набор @xmath44 истинных точек выбирается случайным образом, а затем размазывается, чтобы быть набором @xmath45. три точки, нанесенные на график в каждой ячейке, являются содержимым ячейки при объединении @xmath1 и @xmath3, за которыми следует развернутая оценка содержимого ячейки., title=\"fig:\",scaledwidth=49,0% ] и размытая @xmath43, для (слева) нулевой гипотезы @xmath28 и (справа ) альтернативная гипотеза @xmath32. точки данных: в моделировании mc набор @xmath44 истинных точек выбирается случайным образом, а затем размазывается, чтобы быть набором @xmath45. три точки, нанесенные на график в каждой ячейке, являются содержимым ячейки при объединении @xmath1 и @xmath3, за которыми следует развернутая оценка содержимого ячейки., title=\"fig:\",scaledwidth=49,0% ] для значений параметров по умолчанию в таблице [ базовый уровень ]. (справа ) для каждой ячейки в измеренном значении @xmath1 доля событий, поступающих из этой ячейки (доминирующий цвет) и из близлежащих ячеек., title=\"fig:\",scaledwidth=49,0% ] для значений параметров по умолчанию в таблице [ базовый уровень ]. (справа ) для каждой ячейки в измеренном значении @xmath1 доля событий, поступающих из этой ячейки (доминирующий цвет) и из близлежащих ячеек., title=\"fig:\",scaledwidth=49,0% ] граничные эффекты на концах гистограммы являются важной частью реальной проблемы. в наших упрощенных игрушечных задачах мы используем то же размытие для событий вблизи границ, что и для всех событий (следовательно, некорректно моделируем некоторые физические ситуации, когда наблюдаемые значения не могут быть меньше нуля); события, которые размыты до значений за пределами гистограммы, считаются потерянными и способствуют неэффективности, включенной в @xmath9. эти игрушечные модели запечатлевают некоторую импозантностьважные аспекты реальных проблем в hep. например, можно сравнить генераторы событий для производства топ - кварков в стандартной модели. переменная @xmath1 может быть поперечным импульсом верхнего кварка, а две гипотезы могут быть двумя вычислениями, одно из которых относится к более высокому порядку.    другая реальная проблема может заключаться в том, что @xmath1 представляет поперечный импульс струй, нулевая гипотеза - это стандартная модель, а альтернативная гипотеза - это некоторая физика нестандартной модели, которая включается при высоком поперечном импульсе. (в этом случае обычно не известно, известна ли амплитуда @xmath35 дополнительной физики. ) при типичном поиске физики нестандартной модели проверка гипотезы @xmath28 против @xmath32 формулируется в размытом пространстве, т.е. путем сравнения содержимого гистограммы @xmath26 со средним содержимым ячейки @xmath43, предсказанным истинными плотностями @xmath2 при каждой гипотезе в сочетании с функцией разрешения и никаких потерь эффективности. вероятность @xmath46 для нулевой гипотезы является произведением по ячейкам пуассоновской вероятности получения наблюдаемых значений ячеек : @xmath47, где @xmath48 взяты из предсказания нулевой гипотезы. вероятности для других гипотез, таких как @xmath49, строятся аналогично.    для проверки правильности соответствия может быть полезно @xcite использовать наблюдаемые данные для построения третьей гипотезы, @xmath50, соответствующей _ насыщенной модели _ @xcite, которая устанавливает, что прогнозируемое среднее содержимое ячейки в точности соответствует наблюдаемому. таким образом, @xmath51 является верхней границей @xmath52 для любой гипотезы, учитывая наблюдаемые данные. отрицательное логарифмическое отношение правдоподобия @xmath53 - это тестовая статистика соответствия, которая асимптотически распределяется в виде квадратичного распределения, если @xmath28 истинно. аналогично, у вас есть @xmath54 для тестирования @xmath32. альтернативной (на самом деле более старой) статистикой соответствия тесту является pearson chisquare @ xcite, @ xmath55 еще одна альтернатива, как правило, менее предпочтительная, известна как neyman's chisquare @xcite, @xmath56 ссылка. @xcite утверждает, что уравнение. [ бейкер ] является наиболее подходящей статистикой gof для гистограмм с распределением Пуассона, и мы используем ее в качестве нашей точки отсчета в размытом пространстве. на рисунке [ nullgofsmeared ] показаны распределения @xmath57 и @xmath58 и их разница для гистограмм, сгенерированных в @xmath28. оба распределения соответствуют ожидаемому распределению @xmath59 с 10 степенями свободы (dof). напротив, гистограмма @xmath60 (рисунок [ nullgofsmeared ] (внизу слева ) ) имеет заметные отличия от теоретической кривой. В размытом пространстве со значением по умолчанию gaussian @xmath42 гистограммы статистики теста gof: (вверху слева) @xmath57, ( вверху справа) @xmath58, и (внизу слева ) @xmath60. сплошные кривые представляют собой квадратичное распределение с коэффициентом 10. (внизу справа ) гистограмма разницы от события к событию в двух статистических данных теста gof @xmath58 и @xmath57., title=\"fig:\",scaledwidth=49,0% ], в размытом пространстве со значением по умолчанию gaussian @xmath42, гистограммы статистики теста gof : ( вверху слева ) @xmath57, (вверху справа ) @xmath58 и ( внизу слева ) @xmath60. сплошные кривые представляют собой квадратичное распределение с коэффициентом 10. (внизу справа ) гистограмма разницы от события к событию в двух статистических данных теста gof @xmath58 и @xmath57., title=\"fig:\",scaledwidth=49,0% ], в размытом пространстве со значением по умолчанию gaussian @xmath42, гистограммы статистики теста gof : ( вверху слева ) @xmath57, (вверху справа ) @xmath58 и ( внизу слева ) @xmath60. сплошные кривые представляют собой квадратичное распределение с коэффициентом 10. (внизу справа ) гистограмма разницы от события к событию в двух статистических данных теста gof @xmath58 и @xmath57., title=\"fig:\",scaledwidth=49,0% ], в размытом пространстве со значением по умолчанию gaussian @xmath42, гистограммы статистики теста gof : ( вверху слева ) @xmath57, (вверху справа ) @xmath58 и ( внизу слева ) @xmath60. сплошные кривые представляют собой квадратичное распределение с коэффициентом 10. (внизу справа ) гистограмма разницы от события к событию в двух тестовых статистиках gof @xmath58 и @xmath57., title=\"fig:\",scaledwidth=49,0% ] для тестирования @xmath28 против @xmath32 подходящей тестовой статистикой является отношение правдоподобия @xmath61, сформированное из вероятностей из получения содержимого ячейки @xmath26 при каждой гипотезе : @xmath62, где второе равенство следует из уравнения. [ baker ]. на рисунке [ lambdah0h1 ] показано распределение @xmath63 для событий, сгенерированных в @xmath28, и для событий, сгенерированных в @xmath32, с использованием значений параметров по умолчанию в таблице [ базовый уровень].     для событий, сгенерированных в @xmath28 (синим цветом) и @xmath32 (красным цветом )., scaledwidth=49,0% ] мы бы утверждали, что эти результаты, полученные в размытом пространстве, являются `правильными ответами\" для chisquare - подобных тестов gof @xmath28 и @xmath32 (при желании), и в в частности, для теста отношения правдоподобия @xmath28 против @xmath32 на рис.  [ lambdah0h1 ]. учитывая конкретный наблюдаемый набор данных, такие гистограммы можно использовать для вычисления @xmath64-значений для каждой гипотезы, просто интегрируя соответствующий конец гистограммы за пределы наблюдаемого значения соответствующего отношения правдоподобия @xcite. в частотной статистике такие значения @xmath64 обычно являются основой для логического вывода, особенно для рассмотренных здесь тестов гипотез \"просто против простого\". (конечно, существует обширная литература, ставящая под сомнение основы использования @xmath64-values, но в этой заметке мы предполагаем, что они могут быть полезны, и заинтересованы в сравнении способов их вычисления. ) мы сравниваем @xmath65, @xmath58, @xmath60 и обобщение уравнения. [ chisq ] включая корреляции в различных контекстах ниже. для данных с распределением по Пуассону аргументы в пользу @xmath65, когда он доступен, приведены в ссылке. @xcite.      в обычном тесте @xmath59 gof с (некоррелированными) оценками @xmath66, имеющими _ gaussian _ плотности со стандартными отклонениями @xmath67, обычно используется @xmath68, хотя обычно это не упоминается, это эквивалентно тесту отношения правдоподобия по отношению к насыщенной модели, точно так же, как в случае Пуассона. вероятность равна @xmath69, где для @xmath46 есть @xmath48, предсказанный @xmath28, а для насыщенной модели есть @xmath70. таким образом, @xmath71 и, следовательно, @xmath72 (иногда говорят вольно и неправильно, что для гауссовской модели @xmath73, но очевидно, что соотношение необходимо для отмены коэффициента нормализации. ) также существует хорошо известная связь между обычным гауссовым @xmath59 из уравнения. [ chisq ] и числовым квадратом Пирсона в уравнении. [ пирсон ]: поскольку дисперсия распределения Пуассона равна его среднему значению, наивный вывод уравнения n. [ пирсон ] непосредственно следует из уравнения n. [ chisq ]. если дополнительно аппроксимировать @ xmath48 оценкой @xmath74, то можно получить квадрат Неймана в уравнении. [ нейман ]. если кто-то разворачивает гистограммы, а затем сравнивает развернутые гистограммы @xmath16 с (никогда не размытыми) предсказаниями модели @xmath75, даже неофициально, то он неявно предполагает, что сравнение имеет научный смысл. чтобы это было так, мы бы утверждали, что результаты сравнений не должны существенно отличаться от `правильных ответов\", полученных выше в размытом пространстве. здесь мы рассмотрим несколько тестовых примеров.    учитывая наблюдаемое содержимое гистограммы @xmath26, функция правдоподобия для неизвестного @xmath76 следует из уравнения. [ poisprob ] и приводит к оценкам максимального правдоподобия ( ml ) @xmath77, т.е. @xmath78, тогда можно было бы ожидать, что оценки ml неизвестных средств @xmath14 могут быть получены путем замены @xmath66 на @xmath26 в уравнении.  [ nurmu ]. если @xmath9 является квадратной матрицей, как предполагается здесь, то это дает @ xmath79 это действительно оценки ml для @ xmath14, если @xmath9 обратим, а оценки @xmath80 положительны @xcite, что обычно имеет место в рассматриваемой здесь задаче с игрушками. ковариационная матрица оценок @xmath16 в терминах @xmath9 и @xmath76 получена в ссылке. @xcite : @xmath81, где @xmath82. поскольку истинные значения @xmath76 предположительно неизвестны, естественно заменить оценки из уравнения.  [ nun ], таким образом, получив оценку @xmath18. последствия этого приближения обсуждаются ниже.    во всех случаях (даже когда инверсия матрицы терпит неудачу) оценки ml для @xmath14 могут быть найдены с требуемой точностью с помощью итерационного метода, по-разному известного как максимизация математического ожидания @xcite (em), Люси - Ричардсон или (в hep) итерационный метод дагостини @xcite. поскольку в названии ссылки. @xcite упоминается теорема Байеса, в hep метод em, к сожалению (и ошибочно), упоминается как `байесовский\", хотя это полностью частотный алгоритм @xcite. как обсуждалось cowan @xcite, оценки ml являются непредвзятыми, но непредвзятость может быть достигнута ценой большой дисперсии, которая делает развернутую гистограмму непонятной для людей. поэтому существует обширная литература по `методам регуляризации\", которые уменьшают дисперсию ценой увеличения смещения, так что среднеквадратичная ошибка (сумма квадрата смещения и дисперсии) (можно надеяться) уменьшается. метод регуляризации, популяризированный в hep Дагостини @xcite (и изученный, например, Бомом и Зехом @xcite), заключается просто в остановке итеративного метода em до того, как он сойдет к решению ml. оценки @xmath83 затем сохраняют некоторую память о начальной точке решения (обычно приводящей к смещению) и имеют меньшую дисперсию. неопределенности (ковариационная матрица) также зависят от того, когда итерация останавливается.    наши исследования в этой заметке сосредоточены на ml и усеченных итеративных решениях em и используют реализацию em (к сожалению, называемую roounfoldbayes) в наборе инструментов развертывания roounfold @xcite. это означает, что для настоящих исследований мы ограничены политикой roounfold использовать `истинность\" обучающей выборки в качестве отправной точки для итеративного метода em; таким образом, мы не изучали сходимостьисходить, например, из равномерного распределения. таким образом, полезные исследования смещения оценок не проводятся. другие популярные методы в hep включают варианты регуляризации Тихонова, такие как метод `svd\", пропагандируемый Хокером и Картвелишвили @xcite, и реализация, включенная в tunfold @xcite. связь этих методов с методами, используемыми в профессиональной статистической литературе, обсуждается Кууселой @xcite. на рисунке [ гистограммы ] показаны (в дополнение к сплошным гистограммам, упомянутым выше) три точки с полосами ошибок, нанесенными в каждой ячейке, рассчитанные на основе определенного набора смоделированных данных, соответствующих одному эксперименту. эти три точки представляют собой содержимое ячейки при объединении выборочных значений @xmath1 и @xmath3, за которыми следуют компоненты этой ячейки из набора развернутых оценок @xmath16. на рисунке [ matricesinvert](слева ) показана ковариационная матрица @xmath18 для оценок @xmath16, полученных для того же конкретного набора смоделированных данных, развернутая с помощью матричной инверсии (уравнение. [ nurmuinv ] ) для получения оценок ml. на рисунке [ matricesinvert ] ( справа ) показана соответствующая корреляционная матрица с элементами @xmath84. на рисунке [ matricesiterative ] показаны соответствующие матрицы, полученные при развертывании итерационным методом em с количеством итераций по умолчанию. для решения ml соседние ячейки отрицательно коррелируют, в то время как для решения em с итерациями по умолчанию ( 4) соседние ячейки положительно коррелируют из-за неявной регуляризации.     для развернутых оценок, как это предусмотрено оценками ml (инверсия матрицы). ( справа ) корреляционная матрица, соответствующая @xmath18, с элементами @xmath84., title=\"fig:\",scaledwidth=49,0% ] для развернутых оценок, как это предусмотрено оценками ml (матричная инверсия). ( справа ) корреляционная матрица, соответствующая @xmath18, с элементами @xmath84., title=\"fig:\",scaledwidth=49,0% ] для развернутых оценок, как предусмотрено итеративным методом em по умолчанию. ( справа ) корреляционная матрица, соответствующая @xmath18, с элементами @xmath84., title=\"fig:\",scaledwidth=49,0% ] для развернутых оценок, как предусмотрено итеративным методом em по умолчанию. ( справа ) корреляционная матрица, соответствующая @xmath18, с элементами @xmath84., title=\"fig:\",scaledwidth=49,0% ] на рисунке [ converge ] показан пример сходимости итеративного развертывания em к решению ml для одного смоделированного набора данных. слева представлена дробная разница между решениями em и ml для каждого из десяти блоков гистограммы в зависимости от количества итераций, достигающих численной точности вычисления. справа приведена ковариационная матрица @xmath18 после большого числа итераций, показывающая сходимость к той, которая получена путем инверсии матрицы на фиг. [ matricesinvert](слева )., title=\"fig:\",scaledwidth=49,0% ] (слева )., title=\"fig:\",scaledwidth=49,0% ] хотя решение ml для @xmath16 может быть трудным для визуального изучения человеком, если ковариационная матрица @xmath15 если он ведет себя достаточно хорошо, то компьютер может легко вычислить статистику теста chisquare gof в развернутом пространстве, используя обобщение уравнения. [ chisq ], а именно обычная формула для gof гауссовских измерений с корреляциями @xcite, @xmath85, если развертывание выполняется путем инверсии матрицы (когда равно раствору ml ), затем подставляя @xmath86 из уравнения. [ nurmuinv ], @xmath87 из eqn. [ nurmu ] и @xmath88 из eqn. [ covmu ], дает @xmath89, поэтому для @xmath82, как предположил Коуэн, этот @xmath90, вычисленный в развернутом пространстве, равен квадрату Пирсона ( уравнение. [ пирсон ] ) в размытом пространстве. если, однако, заменить @xmath91 на @xmath43, как в уравнении. [ nun ], тогда @xmath90 в развернутом пространстве равно квадрату Неймана в размытом пространстве! это имеет место в реализации roounfold, которую мы используем, как отмечено ниже на рисунках.    для событий, развернутых с оценками ml, на рисунке [ nulgofunfoldedinvert ] (вверху слева) показаны результаты такого теста @xmath90 gof в отношении нулевой гипотезы с использованием тех же событий, что и на фиг. [ nullgofsmeared ]. как и предполагалось, гистограмма идентична (за исключением числовых артефактов) гистограмме @xmath60 на рис. [ nullgofsmeared ] ( внизу слева ). на рисунке [ nulgofunfoldedinvert ] (вверху справа) показана разница между @xmath90 и @xmath59 Пирсона в размытом пространстве, а на рисунке [ nulgofunfoldedinvert ] (внизу ) показана разница по отношению к @xmath57 в размытом пространстве. на рисунке [ nulgofunfolded ] показаны те же величины, рассчитанные после развертывания с использованием итеративного метода em с итерациями по умолчанию.    для этих тестов с использованием развертывания ml заметная разница между тестом gof в размытом пространстве и тестом в развернутом пространстве напрямую связана с тем фактом, что тест в развернутом пространстве эквивалентен @xmath60 в размытом пространстве, что является худшим тестом gof по сравнению со статистикой теста отношения правдоподобия @xmath92. кажется примечательным, что, несмотря на то, что развертывание с помощью матричной инверсии, казалось бы, не приводит к потере информации, на практике способ использования информации (линеаризация задачи путем выражения результата с помощью ковариационной матрицы) уже приводит к некоторым сбоям в итоговом тесте gof. это без какой-либо регуляризации или приблизительной инверсии em. это проверяет совместимость с @xmath28 в развернутом пространстве для тех же событий, сгенерированных в @xmath28, что и те, которые использовались в тесте размытого пространства на фиг. [ nullgofsmeared ]. ( вверху справа ) для этих событий гистограмма разницы между @xmath90 в развернутом пространстве и @xmath58 в размытом пространстве. (внизу ) для этих событий гистограмма разницы между @xmath90 в развернутом пространстве и статистикой теста gof @xmath92 в размытом пространстве., title=\"fig:\",scaledwidth=49,0% ], которая проверяет совместимость с @xmath28 в развернутом пространстве, для тех же событий, сгенерированных под @xmath28, как те, которые использовались в тесте размазанного пространства на рис. [ nullgofsmeared ]. ( вверху справа ) для этих событий гистограмма разницы между @xmath90 в развернутом пространстве и @xmath58 в размытом пространстве. (внизу ) для этих событий гистограмма разницы между @xmath90 в развернутом пространстве и статистикой теста gof @xmath92 в размытом пространстве., title=\"fig:\",scaledwidth=49,0% ], которая проверяет совместимость с @xmath28 в развернутом пространстве, для тех же событий, сгенерированных под @xmath28, как те, которые использовались в тесте размазанного пространства на рис. [ nullgofsmeared ]. ( вверху справа ) для этих событий гистограмма разницы между @xmath90 в развернутом пространстве и @xmath58 в размытом пространстве. (внизу ) для этих событий гистограмма разницы между @xmath90 в развернутом пространстве и статистикой теста gof @xmath92 в размытом пространстве., title=\"fig:\",scaledwidth=49,0% ] , здесь рассчитанная после развертывания с использованием итеративного метода em с (четырьмя) итерациями по умолчанию., title=\"fig:\",scaledwidth=49,0% ], здесь рассчитано после развертывания с использованием итеративного метода em с (четырьмя) итерациями по умолчанию., title=\"fig:\",scaledwidth=49,0% ], здесь рассчитано после развертывания с использованием итеративного метода em с (четырьмя) итерациями по умолчанию., title=\"fig:\",scaledwidth=49,0% ] для гистограммы каждого моделируемого эксперимента статистика gof @xmath90 вычисляется относительно прогноза @xmath28, а также относительно прогноза @xmath32. разница этих двух значений, @xmath93, затем является тестовой статистикой для тестирования @xmath28 против @xmath32, аналогичной тестовой статистике @xmath63. на рисунке [ delchi ] показано, что для тех же событий, что и те, что использованы на рис. [ lambdah0h1 ], гистограммы тестовой статистики @xmath93 в развернутом пространстве для событий, сгенерированных в @xmath28 и в @xmath32, причем @xmath9 вычисляется с использованием @xmath28 и с использованием @xmath32. для рассматриваемой здесь задачи по умолчанию зависимость от @xmath9 невелика. таким образом, если не указано иное, все остальные графики используют @xmath9, рассчитанный по @xmath28.   , гистограмма тестовой статистики @xmath93 в развернутом пространстве для событий, сгенерированных в @xmath28 (синим цветом ) и @xmath32 (красным цветом ), с @xmath9, вычисленной с использованием @xmath28. ( справа ) для тех же событий гистограммы тестовой статистики @xmath93 в развернутом пространстве, с @xmath9, вычисленной с использованием @xmath32., заголовок=\"рис.:\",scaledwidth=49,0% ], гистограмма тестовой статистики @xmath93 в развернутом пространстве, для событий, сгенерированных в @xmath28 ( синим цветом ) и @xmath32 (красным ), причем @xmath9 вычисляется с использованием @xmath28. ( справа ) для тех же событий показаны гистограммы тестовой статистики @xmath93 в развернутом пространстве с @xmath9, рассчитанной с использованием @xmath32., заголовок=\"fig:\",scaledwidth=49,0% ] рисунок [ deldel ] для событий на фиг. [ lambdah0h1 ] и в [ delchi ] гистограммы разницы между событиями @xmath63 и @xmath93. красные кривые соответствуют событиям, сгенерированным в @xmath28, в то время как синие кривые предназначены для событий, сгенерированных в @xmath32. метод развертывания - ml слева и итеративный em справа. это пример \"итогового теста\": получаются ли одинаковые ответы в размазанном и развернутом пространствах? очевидны различия в обоих методах разворачивания. поскольку события, сгенерированные как в @xmath28, так и в @xmath32, смещены в одном направлении, полные последствия не сразу понятны. таким образом, мы переходим к кривым roc или эквивалентным кривым из проверки гипотезы Неймана - Пирсона.     и в [delchi] (слева ) гистограмма разницы между событиями @xmath63 и @xmath93. на левой гистограмме используется развертывание ml, в то время как на правой гистограмме используется итеративное развертывание em., title=\"fig:\",scaledwidth=49,0% ] и в [ delchi](слева ) гистограмма разницы между событиями @xmath63 и @xmath93. на левой гистограмме используется развертывание ml, в то время как на правой гистограмме используется итеративное развертывание em., title=\"рис.:\",scaledwidth=49.0% ] мы можемисследуйте влияние различий, видимых на рис.  [ deldel ] используя язык тестирования гипотезы Неймана - Пирсона, в котором отклоняется @xmath28, если значение тестовой статистики ( @xmath63 в размытом пространстве или @xmath93 в развернутом пространстве ) превышает некоторое критическое значение @xcite. вероятность ошибки типа i @xmath94 - это вероятность отклонения @xmath28, когда оно истинно, также известная как `частота ложных срабатываний\". вероятность ошибки второго типа @xmath95 - это вероятность принятия (не отклонения) @xmath28, когда оно ложно. величина @xmath96 - это _ мощность _ теста, также известная как `истинно положительный показатель\". таким образом, величины @xmath94 и @xmath95 следуют из кумулятивных функций распределения (cdf) гистограмм тестовой статистики. в задачах классификации вне hep обычно строят roc-кривую соотношения истинно положительной частоты и ложноположительной частоты, как показано на рис. рисунок [ alphabeta ] показывает ту же информацию на графике @xmath95 против @xmath94, т.е. с инвертированной вертикальной координатой по сравнению с кривой roc. рисунок [ alphabetaloglog ] - это тот же график, что и на рис. [ алфавит ], причем обе оси имеют логарифмический масштаб. результат этого `итогового теста\", по-видимому, не является драматичным в этом первом примере, и, по-видимому, в нем преобладает разница между основанными на пуассоне @xmath63 и @xmath93, уже присутствующими в решении для развертывания ml, а не дополнительные различия, вызванные усечением решения em. к сожалению, из этого наблюдения нельзя сделать никакого общего вывода, поскольку, как упоминалось выше, используемое здесь развертывание em начинается с истинного распределения в качестве первой оценки. конечно, необходимо изучить другие исходные оценки.     и [ delchi] (слева ), roc-кривые для классификации, выполненные в размытом пространстве (синяя кривая ) и в не размытом пространстве (красная кривая). (слева ) развертывание с помощью ml и (справа ) развертывание с помощью итеративного em., title=\"fig:\",scaledwidth=49,0% ] и [ delchi] (слева ), кривые roc для классификации, выполненные в размытом пространстве (синяя кривая) и в не размытом пространстве (красная кривая). (слева ) развертывание с помощью ml и (справа ) развертывание с помощью итеративного em., title=\"fig:\",scaledwidth=49,0% ] и [delchi](слева ), графики @xmath95 и @xmath94 для классификации, выполненной в размытом пространстве (синяя кривая) и в неразмазанном пространстве пробел ( красная кривая ). (слева ) развертывание с помощью ml и (справа ) развертывание с помощью итеративного em., title=\"fig:\",scaledwidth=49,0% ] и [delchi](слева ), графики @xmath95 и @xmath94 для классификации, выполненной в размытом пространстве (синяя кривая) и в неразмазанном пространстве пробел ( красная кривая ). (слева ) разворачивание с помощью ml и ( справа ) разворачивание с помощью итеративного em., title=\"fig:\",scaledwidth=49,0% ] против @xmath94, как на рис.  [ алфавит ], здесь с логарифмическим масштабом по обеим осям., title=\"рис.:\",scaledwidth=49,0% ] против @xmath94, как на рис.  [ алфавит ], здесь с логарифмическим масштабом по обеим осям., title=\"рис.:\",scaledwidth=49,0% ] поскольку приведенные выше графики образуют базовую линию, мы можем спросить, как изменяются некоторые из приведенных выше графиков при изменении параметров в таблице [ базовая линия ]. рисунок [ sigmaparam ] показывает, в зависимости от параметра размытия по Гауссу @xmath42 изменение результатов gof показано для @xmath97 на 1d-гистограммах на фиг. [ nulgofunfoldedinvert ] ( вверху слева ) и [ nulgofunfoldedinvert ] ( внизу ). события генерируются в @xmath28. используются при размазывании (вертикальная ось). горизонтальные оси такие же, как и на 1d-гистограммах на фиг. [ nulgofunfoldedinvert ] (вверху слева ) и [nulgofunfoldedinvert ] ( внизу ), а именно @xmath90 в развернутом пространстве; и разница относительно @xmath57 в размытом пространстве; для тестов gof относительно @xmath28 с использованием событий, сгенерированных в @xmath28., title=\"fig:\",scaledwidth=49,0% ] используется при размазывании (вертикальная ось ). горизонтальные оси такие же, как и на 1d-гистограммах на фиг. [ nulgofunfoldedinvert ] (вверху слева ) и [nulgofunfoldedinvert ] ( внизу ), а именно @xmath90 в развернутом пространстве; и разница относительно @xmath57 в размытом пространстве; для тестов gof относительно @xmath28 с использованием событий, сгенерированных в @xmath28., title=\"fig:\",scaledwidth=49,0% ] рисунок [ deldelsigma ] показывает изменение одномерной гистограммы на рисунке [ deldel ] с использованием гауссовского @xmath42, используемого при размазывании, как для ml, так и для em развертывания.     используется для размытия (вертикальная ось) 1d-гистограммы на рис. [ deldel ] разницы между событиями @xmath63 и @xmath93. ( справа ) то же количество для итеративного развертывания em., title=\"fig:\",scaledwidth=49,0% ] используется для размытия (вертикальная ось) 1d-гистограммы на рисунке [ deldel ] разницы между событиями @xmath63 и @xmath93. ( справа ) то же количество для итеративного развертывания em., title=\"fig:\",scaledwidth=49,0% ] рисунки [ deldelb ] и [ deldelbiter ] показывают, для развертывания ml и em соответственно, результат итогового теста на рис.  [ deldel ] как функция амплитуды @xmath35 дополнительного члена в @xmath98 в уравнении. [ altp ].     как функция амплитуды @xmath35 дополнительного члена в @xmath98 в уравнении. [ altp ], для ( слева ) @xmath9, полученного из @xmath28, и ( справа ) @xmath9, полученного из @xmath32 ; для развертывания ml., title=\"fig:\",scaledwidth=49,0% ] как функция амплитуды @xmath35 дополнительного члена в @xmath98 в уравнении. [ altp ], для ( слева ) @xmath9, полученного из @xmath28, и ( справа ) @xmath9, полученного из @xmath32; для развертывания ml., title=\"fig:\",scaledwidth=49,0% ] , для итеративного развертывания em., title=\"fig:\",scaledwidth=49,0% ], для итеративного развертывания em., title=\"fig:\",scaledwidth=49,0% ] рисунок [ deldelnummeas ] показывает, для развертывания ml и em, результат итогового теста на рис. [ deldel ] как функция среднего числа событий на гистограмме @xmath26.     в зависимости от количества событий на гистограмме @xmath26, для (слева) развертывания ml и (справа ) итеративного развертывания em., title=\"fig:\",scaledwidth=49,0% ] в зависимости от количества событий на гистограмме @xmath26, для (слева ) развертывание ml и ( справа ) итеративное развертывание em., title=\"fig:\",scaledwidth=49,0% ] рисунок [ deldelreg ] показывает для итеративного развертывания em результат итогового теста на рис. [ deldel ] в зависимости от количества итераций.     как функция количества итераций в (левой) линейной вертикальной шкале и (правой) логарифмической вертикальной шкале., title=\"рис.:\",scaledwidth=49,0% ] как функция количества итераций в (левой) линейной вертикальной шкале и (правой ) логарифмической вертикальной шкале., title=\"рис.:\",scaledwidth=49,0% ] это примечание подробно иллюстрирует некоторые различия, которые могут возникнуть в отношении размытого пространства при проверке гипотез в развернутом пространстве. поскольку в примечании основное внимание уделяется особенно простой проверке гипотез и рассматриваются только решения ml и em, нельзя сделать никаких общих выводов, кроме утверждения о потенциальной полезности `тестов итоговой оценки\". даже в рамках ограничений используемого здесь программного обеспечения roonfold (в частности, что первоначальная оценка для повторение - предполагаемая истина ), мы видим признаки опасности проверки гипотез после их раскрытия. возможно, самое интересное, что следует отметить на данный момент, это то, что развертывание с помощью матричной инверсии (и, следовательно, без регуляризации) приводит в рассматриваемой здесь реализации к обобщенной тестовой статистике @xmath93, которая идентична @xmath60 в размытом пространстве, которое по своей сути уступает @xmath63. потенциально более важная проблема предвзятости из-за регуляризации, влияющей на итоговый тест, еще предстоит изучить. о таких проблемах следует помнить даже при неофициальном сравнении развернутых данных с предсказаниями теории. для количественного сравнения (включая предполагаемое использование развернутых результатов для оценки теоретических прогнозов в будущем), мы считаем, что следует проявлять крайнюю осторожность, в том числе проводить итоговые тесты с различными отклонениями от ожиданий. это относится как к gof-тестам одной гипотезы, так и к сравнениям нескольких гипотез. требуется дополнительная работа, чтобы получить опыт в отношении того, какие проблемы развертывания и методы развертывания дают результаты, которые обеспечивают приемлемую производительность при тестировании итоговых результатов, и какие случаи приводят к серьезным сбоям. как часто предлагается, представление матрицы ответов @xmath9 вместе с размытыми данными может облегчить сравнение с будущими теориями в свернутом пространстве, несмотря на зависимость @xmath9 от истинных PDF-файлов. 

во многих анализах в области физики высоких энергий предпринимаются попытки устранить эффекты размытия данных детектором с помощью методов, называемых `разворачивающимися\" гистограммами, получая таким образом оценки истинных значений содержимого ячейки гистограммы. такие развернутые гистограммы затем сравниваются с теоретическими предсказаниями, либо для оценки соответствия теории, либо для сравнения возможностей двух или более теорий описывать данные. при этом, даже неофициально, проверяются гипотезы. однако более фундаментально обоснованный способ проверки гипотез заключается в искажении теоретических предсказаний путем моделирования отклика детектора и последующего сравнения с данными без раскрытия; это также часто делается в физике высоких энергий, особенно в поисках новой физики. таким образом, можно задать вопрос: в какой степени проверка гипотез после развертывания данных существенно воспроизводит результаты, полученные в результате тестирования путем размывания теоретических предсказаний? мы утверждаем, что этот `итоговый тест\" методов развертывания следует изучать более широко, в дополнение к обычной практике изучения дисперсии и смещения оценок истинного содержимого ячеек гистограммы. мы проиллюстрируем итоговые тесты в простой игрушечной задаче с двумя гипотезами.