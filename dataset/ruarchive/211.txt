учитывая конкурирующие математические модели для описания процесса, мы хотим знать, совместимы ли наши данные с моделями-кандидатами. часто сравнение моделей требует оптимизации и подгонки данных о ходе времени для оценки значений параметров, а затем применения информационного критерия для выбора `наилучшей\" модели @xcite. однако иногда невозможно оценить значение этих неизвестных параметров (например, большое пространство параметров, нелинейная целевая функция, неидентифицируемость и т.д.). проблема параметров побудила к росту областей, в которых нет параметров, таких как теория сетей химических реакций и стехиометрическая теория @xcite. однако многие из этих подходов ограничены сравнением поведения моделей в установившемся режиме @xcite. вдохновленные методами, обычно используемыми в прикладной алгебраической геометрии @xcite и алгебраической статистике @xcite, методы различения моделей без оценки параметров были разработаны для стационарных данных @xcite, применены к моделям в wnt signaling @xcite, а затем обобщены для включения только одной точки данных @xcite. вкратце, эти подходы характеризуют модель @xmath0 только в наблюдаемых переменных @xmath1 с использованием методов вычислительной алгебраической геометрии и проверяют, являются ли данные стационарного состояния копланарными с этой новой характеристикой модели, называемой _ инвариант стационарного состояния _ @xcite. примечательно, что этот метод не требует оценки параметров, а также включает статистическое ограничение для совместимости модели с зашумленными данными.    здесь мы представляем метод сравнения моделей с данными о ходе времени посредством вычисления дифференциального инварианта. мы рассматриваем модели вида @xmath2 и @xmath3, где @xmath4 - известный ввод в систему, @xmath5, @xmath6 - известный вывод (измерение) из системы, @xmath7, @xmath8 - видовые переменные, @xmath9, @xmath10 - неизвестный вектор размерных параметров @xmath11, а функции @xmath12 являются рациональными функциями своих аргументов. динамику модели можно наблюдать в терминах временного ряда, где @xmath13 - входные данные в дискретных точках, а @xmath14 - выходные данные.    в этой настройке мы стремимся охарактеризовать наши модели ode, исключив переменные, которые мы не можем измерить, используя дифференциальное исключение из дифференциальной алгебры. из исключения мы формируем дифференциальный инвариант, где дифференциальные одночлены имеют коэффициенты, которые являются функциями параметров @xmath15. мы получаем систему уравнений в производных 0,1 и более высокого порядка и записываем эту неявную систему уравнений как @xmath16, @xmath7 и называем эти уравнения ввода - вывода нашими дифференциальными инвариантами. в частности, у нас есть уравнения вида : @xmath17, где @xmath18 - рациональные функции параметров, а @xmath19 - дифференциальные одночлены, т.е. одночлены в @xmath20. вскоре мы увидим, что в линейном случае @xmath21 является линейным дифференциальным уравнением. для нелинейных моделей @xmath21 является нелинейным. если мы подставим в дифференциальный инвариант доступные данные в наблюдаемые одночлены для каждого из моментов времени, мы можем сформировать линейную систему уравнений (каждая строка представляет собой другой момент времени). затем мы спрашиваем: существует ли @ xmath22 такой, что @ xmath23. если @xmath24, конечно, мы гарантируется нулевое тривиальное решение, а нетривиальный случай может быть определен с помощью рангового теста (т.е. svd) и может выполнять статистический критерий, разработанный в @xcite, с улучшенной оценкой в @xcite, но для @xmath23 решений может не быть. таким образом, мы должны проверить, является ли линейная система уравнений @xmath23 непротиворечивой, т.е. имеет одно или бесконечно много решений. предполагая, что шум измерения известен, мы выводим статистическое ограничение для случаев, когда модель несовместима с данными. однако предположим, что у вас нет точек данных для производных данных более высокого порядка, тогда их необходимо оценить. мы представляем метод, использующий регрессию гауссовского процесса (gpr) для оценки данных о ходе времени с использованием георадара. поскольку производная от gp также является gp, мы можем оценить производную более высокого порядка данных, а также вносимый шум измерения и оценить ошибку, вносимую во время георадара (таким образом, мы можем оценить производную более высокого порядка от данных). может отбрасывать точки со слишком большой ошибкой оценки георадара ). это позволяет нам вводить производные данные в дифференциальный инвариант и тестировать совместимость модели, используя тест разрешимости со статистическим ограничением, которое мы представляем. мы демонстрируем наш метод на примерах из линейных и нелинейных моделей. теперь мы дадим некоторые общие сведения о дифференциальной алгебре, поскольку решающим шагом в нашем алгоритме является выполнение дифференциального исключения для получения уравнений исключительно в терминах входных переменных, выходных переменных и параметров. по этой причине мы дадим только общие сведения об идеях из дифференциальной алгебры, необходимых для понимания процесса дифференциального исключения. более подробное описание дифференциальной алгебры и алгоритмов, перечисленных ниже, смотрите в @xcite. в дальнейшем мы предполагаем, что читатель знаком с такими понятиями, как _ кольца _ и _ идеалы _, которые очень подробно описаны в @xcite. кольцо @ xmath25 называется _ дифференциальным кольцом _, если существует производная, определенная на @ xmath25, и @xmath25 замкнуто при дифференцировании. дифференциальный идеал _ - это идеал, который замкнут при дифференцировании. полезное описание дифференциального идеала называется _ набором дифференциальных характеристик _, который является конечным описанием, возможно, бесконечного набора дифференциальных многочленов. мы приводим техническое определение из @xcite: пусть @xmath26 - набор дифференциальных многочленов, не обязательно конечный. если @xmath27 является автоматически уменьшаемым набором, таким образом, что в @xmath26 не может быть сформировано автоматически уменьшаемое множество с более низким рангом, то @xmath28 называется набором дифференциальных характеристик.    хорошо известным фактом в дифференциальной алгебре является то, что дифференциальные идеалы не обязательно должны быть конечно порождены @ xcite. однако радикальный дифференциальный идеал конечно порождается базисной теоремой Ритта - рауденбуша @ xcite. этот результат приводит к появлению алгоритма псевдоразрешения Ритта (см. ниже), позволяющего нам вычислить набор дифференциальных характеристик радикального дифференциального идеала. теперь мы опишем различные методы нахождения набора дифференциальных характеристик и другие связанные с ними понятия, а также опишем, почему они имеют отношение к нашей задаче, а именно, их можно использовать для нахождения уравнений \"вход - выход\".    рассмотрим систему ode вида @xmath29 и @xmath30 для @xmath7 с рациональными функциями @xmath31 и @xmath32 их аргументов. пусть наш дифференциальный идеал генерируется дифференциальными многочленами, полученными путем вычитания правой части из системы ode, чтобы получить @xmath33 и @xmath34 для @xmath7. тогда набор дифференциальных характеристик имеет вид @xcite : @xmath35 первые члены @xmath36 набора дифференциальных характеристик, @xmath37, являются теми членами, которые не зависят от переменных состояния и при установке в ноль образуют _ уравнения ввода - вывода _ : @xmath38 в частности, @xmath36 вход - выход уравнения @xmath39 являются полиномиальными уравнениями в переменных @xmath40 с рациональными коэффициентами в векторе параметров @xmath10. обратите внимание, что набор дифференциальных характеристик, как правило, неуникален, но коэффициенты уравнений ввода - вывода могут быть установлены однозначно путем нормализации уравнений, чтобы сделать их моничными. теперь мы обсудим несколько методов нахождения уравнений ввода - вывода. первый метод (алгоритм псевдоразрешения Ритта) может быть использован для нахождения набора дифференциальных характеристик для радикального дифференциального идеала. второй метод (Розенфельдгребнер) дает представление радикала дифференциального идеала как пересечения регулярных дифференциальных идеалов и также может быть использован для нахождения набора дифференциальных характеристик при определенных условиях @ xcite. наконец, мы обсудим базисные методы Грбнера для нахождения уравнений ввода - вывода.      набор дифференциальных характеристик простого дифференциального идеала - это набор образующих для идеального @ xcite. алгоритм нахождения набора дифференциальных характеристик радикального (в частности, простого) дифференциального идеала, сгенерированного конечным набором дифференциальных многочленов, называется алгоритмом псевдоразрешения Ритта. ниже мы подробно опишем процесс, который взят из описания в @xcite. обратите внимание, что наш дифференциальный идеал, описанный выше, является простым дифференциальным идеалом @ xcite. пусть @xmath41 является лидером многочлена @xmath42, который является производной самого высокого ранга от переменных, входящих в этот многочлен. говорят, что многочлен @xmath43 имеет _ более низкий ранг _, чем @xmath42, если @xmath44 или, всякий раз, когда @xmath45, алгебраическая степень лидера @xmath43 меньше алгебраической степени лидера @xmath42. многочлен @xmath43 _ редуцируется по отношению к многочлену _ @xmath42, если @xmath43 не содержит ни лидера @xmath42 с равной или большей алгебраической степенью, ни его производных. если @xmath43 не уменьшен по отношению к @xmath42, он может быть уменьшен с помощью приведенного ниже алгоритма псевдоразделения.    1. если @xmath43 содержит производную @xmath46 @xmath47 от лидера @xmath42, @xmath42 дифференцируется @xmath48 раз, так что его лидер становится @xmath47. 2. умножьте многочлен @xmath43 на коэффициент наибольшей степени @xmath47 ; пусть @xmath49 - остаток от деления этого нового многочлена с помощью @xmath50 по отношению к переменной @xmath47. тогда @xmath49 уменьшается по отношению к @xmath50. многочлен @xmath49 называется _ псевдоразделителем _ псевдоразделения. многочлен @xmath43 заменяется псевдоопределителем @xmath49, и процесс повторяется с использованием @xmath51 вместо @xmath50 и так далее, пока псевдоопределитель не будет уменьшен относительно @xmath42. этот алгоритм применяется к набору дифференциальных многочленов таким образом, что каждый многочлен редуцируется относительно друг друга, образуя автоматически редуцируемый набор. результатом является дифференциальная характеристика sи.      используя пакет differentialalgebra в maple, можно найти представление радикала дифференциального идеала, сгенерированного некоторыми уравнениями, как пересечение радикальных дифференциальных идеалов относительно заданного ранжирования и переписать простой дифференциальный идеал, используя другое ранжирование @xcite. в частности, команда rosenfeldgroebner в maple принимает два аргумента: sys и r, где sys - это список набора дифференциальных уравнений или неравенств, все из которых являются рациональными в независимых и зависимых переменных и их производных, а r - кольцо дифференциальных многочленов, построенное командой differentialring, определяющей независимые и зависимые переменные, и a рейтинг для них @xcite. затем Розенфельдгребнер возвращает представление радикала дифференциального идеала, сгенерированного sys, как пересечение радикальных дифференциальных идеалов, насыщенных мультипликативным семейством, сгенерированным неравенствами, найденными в sys. Это представление состоит из списка регулярных дифференциальных цепочек относительно ранжирования r. Обратите внимание, что Розенфельдгребнер возвращает дифференциальную характеристику устанавливается, является ли дифференциальный идеал простым @xcite.      наконец, для нахождения уравнений ввода - вывода можно использовать как алгебраические, так и дифференциальные базы Грбнера. чтобы использовать алгебраический базис Грбнера, можно взять достаточное количество производных уравнений модели, а затем рассматривать производные переменных как неопределенные в кольце полиномов в @xmath52, @xmath53, @xmath54,..., @xmath55, @xmath56, @xmath57,..., @xmath58, @xmath59, @xmath60,... и т.д. Затем может быть найден базис grbner для идеала, порожденного этой полной системой (дифференциальных) уравнений с порядком исключения, где сначала исключаются переменные состояния и их производные. подробную информацию об этом подходе можно найти в @xcite. дифференциальные базы грбнера были разработаны carr ferro @ xcite, ollivier @xcite и mansfield @xcite, но в настоящее время в системах компьютерной алгебры @xcite нет реализаций. теперь мы обсудим, как использовать дифференциальные инварианты, полученные в результате дифференциального исключения (с использованием псевдоразрешения Ритта, дифференциальных базисов Гребнера или какого-либо другого метода) для выбора/ отбраковки модели. напомним, что наши отношения ввода-вывода, или дифференциальные инварианты, имеют вид: @xmath17 функции @xmath19 являются дифференциальными одночленами, т.е. одночленами в переменных ввода/ вывода @xmath61, @xmath62, @xmath63 и т.д., а функции @xmath18 являются рациональными функциями в векторе неизвестных параметров @xmath10. чтобы однозначно привязать рациональные коэффициенты @xmath18 к дифференциальным одночленам @xmath19, мы нормализуем каждое уравнение ввода / вывода, чтобы сделать его однозначным. другими словами, мы можем переписать наши отношения ввода - вывода следующим образом: @xmath64 здесь @xmath65 - дифференциальный многочлен в переменных ввода-вывода @xmath61, @xmath62, @xmath63 и т.д. Если значения @xmath61,@xmath62, @xmath63 и т.д. были известны в достаточное количество временных интервалов @xmath66, тогда можно было бы подставить значения @xmath19 и @xmath65 в каждый из этих временных интервалов, чтобы получить линейную систему уравнений в переменных @xmath67. сначала рассмотрим случай единственного уравнения \"затраты - выпуск\". если есть неизвестные коэффициенты @xmath68 @xmath67, мы получаем систему : @xmath69 мы записываем эту линейную систему как @xmath23, где @xmath28 - это матрица @xmath70 от @xmath68 вида : @xmath71 @xmath22 - вектор неизвестных коэффициентов @xmath72^t$], и @xmath73 имеет вид @xmath74^t$ ].    для случая множественных уравнений ввода - вывода мы получаем следующую блочно-диагональную систему уравнений @xmath23 : @xmath75, где @xmath28 - это матрица @xmath76 by @xmath77.    для получения данных без помех (идеальных) эта система @xmath23 должна иметь уникальное решение для @xmath22 @xcite. другими словами, коэффициенты @xmath67 уравнений ввода - вывода могут быть однозначно определены из достаточного количества входных / выходных данных @xcite. основная идея этой статьи заключается в следующем. учитывая набор моделей-кандидатов, мы находим связанные с ними дифференциальные инварианты, а затем подставляем значения @xmath20 и т.д. Во многих случаях времени @xmath78, таким образом настраивая линейную систему @xmath23 для каждой модели. решение @xmath23 должно быть уникальным для правильной модели, но не должно быть решения для каждой из неправильных моделей. таким образом, при идеальных обстоятельствах человек должен иметь возможность выбрать правильную модель, поскольку входные/выходные данные, соответствующие этой модели, должны удовлетворять ее дифференциальному инварианту. аналогично, нужно иметь возможность отклонять неправильные модели, поскольку входные/выходные данные не должны удовлетворять их дифференциальным инвариантам. однако при несовершенных данных не может быть решения @xmath23 даже для правильной модели. таким образом, при неполных данных может оказаться невозможным выбрать правильную модель. с другой стороны, если нет решения @xmath23 для каждой из моделей-кандидатов, то цель состоит в том, чтобы определить, насколько `сильно\" каждая из моделей терпит неудачу, и соответственно отклонить модели. теперь мы опишем критерии для отклонения моделей. пусть @xmath80 и рассмотрим линейную систему @xmath81, где @xmath82. Обратите внимание, в нашем случае @xmath83, так что @xmath84 - это просто вектор @xmath73. здесь мы изучаем разрешимость при (определенной форме) возмущения как @xmath28, так и @xmath84. пусть @xmath85 и @xmath86 обозначают возмущенные версии @xmath28 и @xmath84 соответственно и предполагают, что @xmath87 и @xmath88 зависят только от @xmath85 и @xmath86 соответственно. наша цель - сделать вывод о неразрешимости невозмущенной системы только из наблюдений за @xmath85 и @xmath86. мы опишем, как определить ранг расширенной матрицы, но сначала введем обозначения. сингулярные значения матрицы @xmath80 будут обозначаться @xmath89 (обратите внимание, что мы тривиально увеличили число сингулярных значений @xmath28 с @xmath90 до @xmath68. ) ранг @xmath28 записывается как @xmath91. диапазон @xmath28 обозначается как @xmath92. повсюду @xmath93 относится к евклидовой норме. основная стратегия будет заключаться в том, чтобы принять в качестве нулевой гипотезы, которая имеет решение, т.е. @xmath94, а затем вывести ее следствия в терминах @xmath85 и @xmath86. если эти следствия не выполняются, то мы приходим к противоречию, которое неразрешимо. другими словами, мы обеспечим _ достаточные, но не необходимые _ условия для того, чтобы не иметь решения, т.е. мы можем только отклонить (но не подтвердить) нулевую гипотезу. мы будем называть эту процедуру _ проверкой _ нулевой гипотезы. сначала мы собираем некоторые полезные результаты. первое, неравенство Вейля, довольно стандартно. пусть @xmath95. тогда неравенство Вейля @xmath96 можно использовать для проверки @xmath91, используя знание только @xmath85. пусть @xmath97 и предположим, что @xmath98. тогда @xmath99 [ cor : weyl - rank ] следовательно, если не удовлетворяется, то @xmath100. предположим нулевую гипотезу. тогда @xmath94, поэтому @xmath101 ) = \\operatorname{rank}(a ) \\leq \\min ( m, n)$ ]. следовательно, @xmath102 ) = 0 $ ]. но у нас нет доступа к @xmath103 $ ] и поэтому вместо этого мы должны рассмотреть возмущенную дополненную матрицу @xmath104 $ ].    согласно нулевой гипотезе, @xmath105 ) \\leq \\| [ \\tilde{a } - a, \\tilde{b } - b ] \\| \\leq \\| \\tilde{a } - a \\| + \\| \\tilde{b } - b \\|. \\label{eqn : дополненная сигма } \\end{выровнено}\\ ] ] [ thm : дополненная матрица ] применяем следствие [ cor : weyl - rank ].    другими словами, если не выполняется, то не имеет решения. этот подход может не привести к корректному отклонению нулевой гипотезы, если @xmath28 имеет (численно) низкий ранг. в качестве примера предположим, что @xmath106 и пусть @xmath107 состоят из одного вектора ( @xmath108). тогда @xmath101 ) \\leq n$ ], поэтому @xmath102 ) = 0 $ ] ( или мало ). предполагая, что @xmath109 и @xmath110 малы, @xmath111)$ ], следовательно, также будет небольшим.    в принципе, мы должны напрямую проверить утверждение о том, что @xmath101 ) = \\operatorname{rank}(a)$ ]. Однако мы можем установить только нижние границы ранга матрицы (мы можем только определить, является ли сингулярное значение `слишком большим\"), поэтому на практике это неосуществимо. альтернативный подход заключается в рассмотрении только _ числовых _ рангов, полученных с помощью порогового значения. однако, как выбрать такое пороговое значение, совсем не ясно и может быть очень деликатным вопросом, особенно если данные имеют высокий динамический диапазон. теорема неинформативна, если @xmath112 с тех пор @xmath102 ) = \\sigma_{n + 1 } ( \\tilde{a }, \\tilde{b } ) = 0 $ ] тривиально. однако это не является существенным недостатком, помимо описанного выше, поскольку если @xmath28 имеет полный ранг, то это должно быть правдой, которая разрешима.      в качестве доказательства принципа мы сначала применим теорему [ thm : дополненная матрица] к простой линейной модели. мы начинаем с получения идеальных входных и выходных данных, а затем добавляем определенное количество шума к выходным данным и пытаемся отклонить неправильную модель. в последующих разделах мы увидим, как статистически интерпретировать теорему [ thm : дополненная матрица] в рамках конкретной модели `шума\" для возмущений.    здесь мы берем данные из линейной модели с 3 отсеками, добавляем шум и пытаемся отклонить общую форму линейной модели с 2 отсеками с теми же отсеками ввода/вывода. [ пример : mainex ] пусть наша модель представляет собой модель с 3 отсеками следующего вида: @xmath113 @xmath114 здесь у нас есть входные данные для первого отсека формы @xmath115, и измеряется первый отсек, так что @xmath116 представляет выходные данные. решение для этой системы ode можно легко найти в виде : @xmath117, так что @xmath118. уравнение ввода - вывода для модели отсека @xmath119 с одним входом/выходом в первый отсек имеет вид: @xmath120, где @xmath121 - коэффициенты характеристического многочлена матрицы @xmath28 и @xmath122 - коэффициенты характеристического многочлена матрицы @xmath123, которая имеет следующий вид: первая строка и первый столбец @xmath28 удалены. теперь мы подставляем значения @xmath124 во временные экземпляры @xmath125 в наш input - выходное уравнение и решили результирующую линейную систему уравнений для @xmath126. мы получаем, что @xmath127, который согласуется с коэффициентами характеристических многочленов @xmath28 и @xmath123. теперь мы попытаемся отклонить модель с 2 отсеками, используя данные модели с 3 отсеками. мы находим уравнения ввода - вывода для модели отсека @xmath128 с одним входом/выходом в первый отсек, который имеет вид: @xmath129, где снова @xmath130 - коэффициенты характеристического многочлена матрицы @xmath28 и @xmath131 - коэффициент характеристического многочлена матрицы @xmath123, в котором удалены первая строка и первый столбец @xmath28. мы подставляем значения @xmath132 в моменты времени @xmath133 в наше уравнение ввода-вывода и пытаемся решить полученную линейную систему уравнений для @xmath134. сингулярные значения для матрицы @xmath28 с замененными значениями @xmath135 в экземплярах времени @xmath133 следующие : @xmath136 сингулярные значения матрицы @xmath137 с замененными значениями @xmath132 в экземплярах времени @xmath133 следующие : @xmath138 мы добавляем шум к нашей матрице a следующим образом. к каждой записи @xmath139 и @xmath140 мы добавляем @xmath141, где @xmath142 - случайное действительное число между @xmath143 и @xmath144, а @xmath145 равно @xmath146. тогда зашумленная матрица @xmath85 имеет следующие сингулярные значения : @xmath147 теперь мы добавляем шум к нашему вектору @xmath73 следующим образом. к каждой записи @xmath148 мы добавляем @xmath141, где @xmath142 - случайное действительное число между @xmath143 и @xmath144, а @xmath145 равно @xmath146. тогда зашумленная матрица @xmath149 имеет следующие сингулярные значения : @xmath150 мы находим матрицу @xmath151 и сравниваем норму этой матрицы с наименьшим сингулярным значением @xmath149. поскольку норма Фробениуса @xmath151 равна @xmath152, что _ меньше _ наименьшего сингулярного значения @xmath153, мы можем отвергнуть эту модель. таким образом, используя зашумленные данные модели с 3 отсеками, мы можем отклонить модель с 2 отсеками. теперь мы рассмотрим статистический вывод о разрешимости. Во-первых, нам нужна модель с шумом. если возмущения @xmath109 и @xmath110 ограничены, например, @xmath154 и @xmath155 для некоторого @xmath156 (представляющего относительную точность @xmath145 в `измерениях\" @xmath85 и @xmath86 ), то теорема [ thm : дополненная матрица ] может быть использована сразу. однако принято моделировать такие возмущения как обычные случайные величины, которые не ограничены. здесь мы будем предполагать модель шума вида @xmath157, где @xmath158 - это (вычислимая) матрица, которая зависит от @ xmath85 и аналогично с @ xmath159, @xmath160 обозначает матричное произведение Адамара (по входу) @ xmath161, а @xmath162 - матричная случайная величина, записи которой @xmath163 являются независимыми стандартными нормалями.    в интересующем нас приложении записи @xmath158 зависят от записей @xmath85 следующим образом. пусть @xmath164 для некоторого входного вектора @xmath165, но предположим, что мы можем наблюдать только `зашумленный\" вектор @xmath166. тогда соответствующие элементы возмущенной матрицы равны @xmath167 по формуле аддитивности @xmath168 для стандартных гауссианов. однако статистический вывод все еще остается в силе, поскольку @xmath169 `доминирует\" над @xmath170 в том смысле, что первый имеет дисперсию @xmath171, в то время как второй имеет дисперсию только @xmath172. другими словами, мы были неправы, но в консервативном направлении. это было учтено в @xcite. ] @xmath173 следовательно, @xmath174 итак, для первого порядка в @xmath145, @xmath175 аналогичный вывод выполняется для @xmath159. каждая из границ в приведенных выше теоремах линейна в @ xmath109 и @xmath110 (для теоремы [ thm : дополненная матрица ] граница является просто суммой этих двух ) и поэтому может быть записана как @xmath176 путем поглощения констант. основная стратегия на данный момент заключается в следующем. пусть @xmath177 - тестовая статистика, т.е. @xmath111)$ ] в [ sec : расширенная матрица ]. тогда, поскольку @xmath178, где мы явно указали зависимость обеих сторон от одного и того же базового случайного механизма @xmath179, (кумулятивная) функция распределения @xmath177 должна доминировать над функцией распределения @xmath176, т.е. @xmath180 таким образом, @xmath181 [ eqn : prob - tau ] обратите внимание, что если, например, @xmath182 (т.е. если бы @xmath84 был известен точно ), то упрощается просто до @xmath183. используя, мы можем связать значение @xmath184 с любой заданной реализацией @xmath177 путем ссылки на верхние конечные границы для величин вида @xmath185. напомним, что @xmath186 находится в рамках нулевой гипотезы. таким образом, в классической системе проверки статистических гипотез мы можем отклонить нулевую гипотезу, если значение не превышает @xmath187, где @xmath187 - желаемый уровень значимости (например, @xmath188 ). теперь мы перейдем к ограничению @xmath189, где будем предполагать, что @xmath190. это можно сделать несколькими способами. один простой способ - распознать, что @xmath191, где @xmath192 - норма Фробениуса, поэтому @xmath193, но @xmath194 имеет распределение хи). ] с @xmath195 степенями свободы. следовательно, @xmath196 однако, каждое неравенство в может быть довольно свободным: первое является свободным в том смысле, что @xmath197, в то время как второе в том, что @xmath198, но @xmath199 немного лучшим подходом является использование неравенства @xcite @xmath200, где @xmath201 и @xmath202 обозначают @xmath203-ю строку, а @xmath203-ю строку. @xmath204-й столбец, соответственно, из @xmath205. затем термин @xmath206 может быть обработан с использованием распределения chi через @xmath207, как указано выше, или напрямую с использованием ограничения концентрации (см. ниже). варианты этого, несомненно, существуют.    здесь мы обратимся к результату tropp @xcite. следующее взято из 4.3 в @xcite. пусть @xmath190, где каждый @xmath163. тогда для любого @xmath208, @xmath209 [ thm : адамар - гауссиан ] граница для @xmath210 может быть вычислена следующим образом. пусть @xmath211, так что @xmath212. затем по теореме [ thm : адамар - гауссиан ], @xmath213 \\, dt, \\end{выровнено}\\ ] ] где @xmath214 и @xmath215 являются параметрами `дисперсии\" в теореме для @xmath158 и @xmath159 соответственно. термин в круглых скобках упрощается до @xmath216\\\\ & = \\frac{1}{\\sigma_{a}^{2 } \\sigma_{b}^{2 } } \\left [ ( \\sigma_{a}^{2 } + \\sigma_{b}^{2 } ) \\слева ( t - \\frac{\\sigma_{a}^{2}}{\\sigma_{a}^{2 } + \\sigma_{b}^{2 } } x \\справа)^{2 } + \\sigma_{a}^{2 } \\слева ( 1 - \\frac{\\sigma_{a}^{2}}{\\sigma_{a}^{2 } + \\sigma_{b}^{2 } } \\справа ) x^{2 } \\справа]\\\\ & = \\frac{1}{\\sigma_{a}^{2 } \\sigma_{b}^{2 } } \\left [ ( \\sigma_{a}^{2 } + \\sigma_{b}^{2 } ) \\left ( t - \\frac{\\sigma_{a}^{2}}{\\sigma_{a}^{2 } + \\sigma_{b}^{2 } } x \\справа)^{2 } + \\frac{\\sigma_{a}^{2 } \\sigma_{b}^{2}}{\\sigma_{a}^{2 } + \\sigma_{b}^{2 } } x^{2 } \\right]\\\\ & = \\frac{\\sigma_{a}^{2 } + \\sigma_{b}^{2}}{\\sigma_{a}^{2 } \\sigma_{b}^{2 } } \\слева ( t - \\frac{\\sigma_{a}^{2}}{\\sigma_{a}^{2 } + \\sigma_{b}^{2 } } x \\справа)^{2 } + \\frac{x^{2}}{\\sigma_{a}^{2 } + \\sigma_{b}^{2 } } \\end{выровнено}\\ ] ] при заполнении квадрата. следовательно, @xmath217 \\int_{0}^{x } \\exp \\left [ -\\frac{1}{2 } \\left ( \\frac{\\sigma_{a}^{2 } + \\sigma_{b}^{2}}{\\sigma_{a}^{2 } \\sigma_{b}^{2 } } \\справа ) \\слева ( t - \\frac{\\sigma_{a}^{2}}{\\sigma_{a}^{2 } + \\sigma_{b}^{2 } } x \\справа)^{2 } \\справа ] dt. \\end{выровнено}\\ ] ] теперь установите @xmath218 так, чтобы интеграл стал @xmath219 dt = \\int_{0}^{x } \\exp \\left [ -\\frac{(t - \\alpha x)^{2}}{2 \\sigma^{2 } } \\справа ] dt. \\end{выровнено}\\ ] ] подстановка переменной @xmath220 затем дает @xmath221 dt = \\sigma \\int_{-\\alpha x / \\sigma}^{(1 - \\alpha ) x / \\sigma } e^{-u^{2}/2 } \\, du = \\sqrt{2 \\pi } \\sigma \\left [ \\phi \\left ( \\frac{(1 - \\alpha ) x}{\\sigma } \\right ) - \\phi \\left ( -\\frac{\\alpha x}{\\sigma } \\right ) \\right ], \\end{выровнено}\\ ] ] где @xmath222 - стандартная функция нормального распределения. таким образом, @xmath223 \\exp \\left [ -\\frac{1}{2 } \\left ( \\frac{x^{2}}{\\sigma_{a}^{2 } + \\sigma_{b}^{2 } } \\right ) \\right ]. \\label{eqn : p1 } \\end{выровнено}\\ ] ] аналогичный (но гораздо более простой) анализ приводит к @xmath224 далее мы представляем метод оценки производных более высокого порядка и ошибки оценки с использованием регрессии гауссовского процесса, а затем применяем дифференциально-инвариантный метод как к линейным, так и к нелинейным моделям в последующих разделах.    гауссовский процесс (gp) - это стохастический процесс @xmath225, где @xmath226 - функция среднего значения, а @xmath227 - функция ковариации. gps часто используются для регрессии / прогнозирования следующим образом. предположим, что существует лежащая в основе детерминированная функция @xmath228, которую мы можем наблюдать только с некоторым шумом измерения, как @xmath229, где @xmath230 для @xmath231 - дельта Дирака. мы рассматриваем проблему нахождения @xmath228 в байесовской постановке, предполагая, что это gp с априорными средними и ковариационными функциями @xmath232 и @xmath233 соответственно. затем совместное распределение @xmath234^{{\\mathsf{t}}}$ ] в точках наблюдения @xmath235^{{\\mathsf{t}}}$ ] и @xmath236^{{\\mathsf{t}}}$ ] в точках прогнозирования @xmath237^{{\\mathsf{t}}}$ ] является @xmath238 условное распределение @xmath239, заданное @xmath240, также является гауссовым : @xmath241, где @xmath242 - апостериорное среднее и ковариация соответственно. это позволяет нам вывести @xmath239 на основе наблюдения @xmath243. диагональные элементы @xmath244 представляют собой апостериорные отклонения и количественно определяют неопределенность, связанную с этой процедурой вывода. уравнение предоставляет оценку значений функции @xmath239. что, если мы хотим оценить ее производные? пусть @xmath245 для некоторой ковариационной функции @xmath48. затем @xmath246 по линейности дифференцирования. таким образом, @xmath247 \\hat{x } ( \\boldsymbol{t } ) \\cr\\- x(\\boldsymbol{s } ) \\cr x'(\\boldsymbol{s } ) \\cr \\vdots \\cr x^{(n ) } ( \\boldsymbol{s } ) \\cr \\end{pmat } \\sim { \\mathcal{n}}\\left ( \\begin{pmat}[{. } ] \\mu_{{\\текст{предыдущий } } } ( \\жирный символ{t } ) \\cr\\- \\mu_{{\\текст{предыдущий } } } ( \\жирный символ{s } ) \\cr \\mu_{{\\текст{предыдущий}}}^{(1 ) } ( \\жирный символ{s } ) \\cr \\vdots \\cr \\mu_{{\\текст{предыдущий}}}^{(n ) } ( \\жирный символ{s } ) \\cr \\end{pmat }, \\begin{pmat}[{|... } ] \\sigma_{{\\текст{до } } } ( \\boldsymbol{Т }, \\boldsymbol{Т } ) + \\сигма^{2 } ( \\boldsymbol{т } ) я & \\sigma_{{\\текст{до}}}^{{\\mathsf{Т } } } ( \\boldsymbol{х }, \\boldsymbol{Т } ) & \\sigma_{{\\текст{до}}}^{(1,0),{\\mathsf{Т } } } ( \\boldsymbol{х }, \\boldsymbol{Т } ) & \\cdots & \\sigma_{{\\текст{до}}}^{(П,0 ), { \\mathsf{Т } } } ( \\boldsymbol{х }, \\boldsymbol{Т } ) \\КР\\- \\sigma_{{\\текст{до } } } ( \\boldsymbol{х }, \\boldsymbol{Т } ) & \\sigma_{{\\текст{до } } } ( \\boldsymbol{х }, \\boldsymbol{х } ) & \\sigma_{{\\текст{до}}}^{(1,0 ), { \\mathsf{Т } } } ( \\boldsymbol{х }, \\boldsymbol{х } ) & \\cdots & \\sigma_{{\\текст{до}}}^{(П,0 ), { \\mathsf{Т } } } ( \\boldsymbol{х }, \\boldsymbol{х } ) \\КР \\sigma_{{\\текст{до}}}^{(1,0 ) } ( \\boldsymbol{х }, \\boldsymbol{Т } ) & \\sigma_{{\\текст{до}}}^{(1,0 ) } ( \\boldsymbol{х }, \\boldsymbol{х } ) & \\sigma_{{\\текст{до}}}^{(1,1 ) } ( \\boldsymbol{х }, \\boldsymbol{х } ) & \\cdots & \\sigma_{{\\текст{до}}}^{(п,1 ), { \\mathsf{Т } } } ( \\boldsymbol{х }, \\boldsymbol{х } ) \\КР \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\КР \\sigma_{{\\текст{до}}}^{(П,0 ) } ( \\boldsymbol{х }, \\boldsymbol{Т } ) & \\sigma_{{\\текст{до}}}^{(П,0 ) } ( \\boldsymbol{х }, \\boldsymbol{х } ) & \\sigma_{{\\текст{до}}}^{(п,1 ) } ( \\boldsymbol{х }, \\boldsymbol{х } ) & \\cdots & \\sigma_{(п, п ) } ( \\boldsymbol{х }, \\boldsymbol{х } ) \\КР \\конец{pmat } право\\), \\конец{выровнены}\\ ] ], где @xmath248 это до означать для @xmath249 и @xmath250. это совместное распределение в точности имеет вид. аналогичное применение then дает апостериорную оценку @xmath251 для всех @xmath252. в качестве альтернативы, если нас интересуют только апостериорные отклонения каждого @xmath253, тогда достаточно рассмотреть каждый блок @xmath254 независимо : @xmath255 стоимость вычисления @xmath256 явно может быть амортизирована по всем @xmath203. теперь мы рассмотрим конкретный случай квадратичной экспоненциальной (se) ковариационной функции @xmath257, \\end{выровнено}\\ ] ], где @xmath258 - дисперсия сигнала, а @xmath90 - шкала длины. функция se является одной из наиболее широко используемых ковариационных функций на практике. ее производные могут быть выражены в терминах (вероятностных) многочленов Эрмита @xmath259 (их также иногда обозначают @xmath260). первые несколько многочленов Эрмита - это @xmath261, @xmath262 и @xmath263. нам нужно вычислить производные @xmath264. пусть @xmath265, чтобы @xmath266. затем @xmath267 и @xmath268. следовательно, @xmath269 для регрессии gp требуется, чтобы у нас были значения гиперпараметров @xmath270, @xmath271 и @xmath90. однако на практике они практически никогда не известны. в приведенных ниже примерах мы решаем эту проблему, оценивая гиперпараметры на основе данных путем максимизации вероятности. мы делаем это с помощью алгоритма нелинейного сопряженного градиента, который может быть весьма чувствителен к начальной начальной точке, поэтому мы инициализируем несколько прогонов по небольшой сетке в пространстве гиперпараметров и возвращаем найденную наилучшую оценку. это повышает качество оцениваемых гиперпараметров, но все равно иногда может давать сбой. мы демонстрируем наш метод на конкурирующих моделях: линейных моделях отсеков (2 и 3 вида), моделях Лотки - Вольтерры (2 и 3 вида) и Лоренца. поскольку дифференциальные инварианты линейных отсеков были представлены в предыдущем разделе, мы вычисляем дифференциальные инварианты лотки - вольтерры и Лоренца, используя Розенфельдгребнера. мы моделируем каждую из этих моделей для генерации данных о ходе времени, добавляем различные уровни шума и оцениваем необходимые производные более высокого порядка с помощью gp-регрессии. как описано в предыдущем разделе, мы требуем, чтобы оценка производных более высокого порядка удовлетворяла отрицательному логарифмическому значению правдоподобия, в противном случае соответствие gp не является \"хорошим\". в некоторых случаях это можно исправить, увеличив количество точек данных. используя оцененные данные регрессии gp, мы тестируем каждую из моделей, используя дифференциально-инвариантный метод, на других моделях. [ пример : lv2 ] модель Лотки - Вольтерры двух видов такова: @xmath272, где @xmath273 и @xmath274 - переменные, а @xmath275 - параметры. мы предполагаем, что наблюдаем только @xmath273, и выполняем дифференциальное исключение и получаем наш дифференциальный инвариант в терминах только @xmath276 : @xmath277 [ пример : lv3 ] путем включения дополнительной переменной @xmath278, модель Лотки - Вольтерры трех видов: @xmath279 предполагая, что наблюдаем только @xmath116. после дифференциального исключения дифференциальный инвариант равен: @xmath280 [ пример : lor ] другая модель из трех видов, модель Лоренца, описывается системой уравнений : @xmath281 мы предполагаем, что наблюдаем только @xmath116, выполняем дифференциальное исключение и получаем следующий инвариант: @xmath282 [ пример: lc2 ] линейная модель с 2 отсеками без ввода может быть записана как : @xmath283, где @xmath273 и @xmath274 - переменные, а @xmath284 - параметры. мы предполагаем, что наблюдаем только @xmath273, и выполняем дифференциальное исключение и получаем наш дифференциальный инвариант в терминах только @xmath276 : @xmath285 [ пример : lc3 ] линейная модель с 3 отсеками без ввода : @xmath286, где @xmath287 - переменные, а @xmath288 - параметры. мы предполагаем, что только @xmath273 является наблюдаемой, и выполняем дифференциальное исключение и получаем наш дифференциальный инвариант в терминах только @xmath276 : @xmath289 предполагая, что @xmath116 в примерах 6.16.5 представляет одну и ту же наблюдаемую переменную, мы применяем наш метод к данным, смоделированным из каждой модели, и выполняем сравнение моделей. модели моделируются, и в каждой модели получается 100 временных точек с переменной @xmath165. мы добавляем различные уровни гауссовского шума к моделируемым данным, а затем оцениваем производные более высокого порядка из данных. например, в ходе нашего исследования мы обнаружили, что для некоторых параметров модели трех видов Лотки - Вольтерры, например, @xmath290 $ ], мы получили положительное логарифмическое правдоподобие, что означало, что мы не могли оценить производные более высокого порядка данных. как только данные получены и производные данные оценены с помощью регрессии gp, каждый набор данных модели проверяется на соответствие другим дифференциальным инвариантам. результаты показаны на рисунке [рис. 4 ], где значение 0 означает, что модель отклонена, а 1 означает, что модель совместима. мы обнаружили, что можем отклонить модель Лотки - Вольтерры для трех видов и модель Лоренца для данных, смоделированных для двух видов лотки - вольтерры; однако обе модели линейных отсеков совместимы. для данных из модели Лотки - вольтерры с тремя видами модели линейных отсеков и модели лотки - вольтерры с двумя видами могут быть отклонены до тех пор, пока шум не увеличится, и тогда метод больше не сможет отклонять какие-либо модели. наконец, данные, сгенерированные из модели Лоренца, могут отклонять только линейный отсек для двух видов и модель Лотки - Вольтерры для двух видов. $ ] и начальное условие @xmath291 $ ]. (b ) данные, смоделированные на основе модели Лотки - Вольтерры трех видов со значениями параметров [xmath292 $ ] и начальным условием [xmath293 $ ]. ( c ) данные, смоделированные по модели Лоренца со значениями параметров @xmath294 $ ] и начальным условием @xmath293 $ ]. (d ) данные, смоделированные из модели линейного отсека с тремя видами со значениями параметров @xmath295 $ ] и начальным условием @xmath296 $ ]. ] мы продемонстрировали наш алгоритм распознавания моделей на различных моделях. в этом разделе мы рассмотрим некоторые другие теоретические моменты, касающиеся дифференциальных инвариантов.    обратите внимание, что мы предположили, что все параметры неизвестны, и мы не учли никаких возможных алгебраических зависимостей между коэффициентами. этот последний момент является еще одной причиной, по которой наш алгоритм касается только отклонения модели, а не выбора модели. таким образом, каждый неизвестный коэффициент необходимо рассматривать как независимую неизвестную переменную в нашей линейной системе уравнений. однако могут быть случаи, когда мы хотели бы рассмотреть возможность включения этой дополнительной информации. сначала мы рассмотрим эффект включения известных значений параметров.    в @xcite была выведена явная формула для уравнений ввода - вывода для линейных моделей. в частности, было показано, что все линейные модели @xmath297compartment, соответствующие сильно связанным графам по крайней мере с одной утечкой и имеющие одинаковые входные и выходные отсеки, будут иметь одинаковую дифференциальную полиномиальную форму уравнений ввода - вывода. например, линейная модель из 2 отсеков с одним входом и выходом в одном отсеке и соответствующая сильно связанному графу по крайней мере с одной утечкой имеет вид: @xmath298 таким образом, наш метод распознавания модели не будет работать для двух различных линейных моделей из 2 отсеков с вышеупомянутой формой. чтобы провести различие между двумя такими моделями, нам необходимо принять во внимание другую информацию, например, известные значения параметров. рассмотрим следующие две линейные модели с 2 отсеками: @xmath299 @xmath300, соответствующие уравнения ввода - вывода которых имеют вид : @xmath301 обратите внимание, что оба этих уравнения имеют вышеупомянутый вид, т.е. обе модели с 2 отсеками имеют один вход и выход в одном отсеке и соответствуют сильно связанные графики по крайней мере с одной утечкой. в первой модели происходит утечка из первого отсека и обмен между отсеками @xmath144 и @xmath128. во второй модели происходит утечка из второго отсека и обмен данными между отсеками @xmath144 и @xmath128. предположим, что параметр @xmath302 известен. в первой модели это изменяет наш инвариант на : @xmath303 во второй модели наш инвариант равен: @xmath304 в этом случае правые части двух уравнений одинаковы, но первое уравнение имеет две переменные (коэффициенты), в то время как второе уравнение имеет три переменные (коэффициенты ). таким образом, если бы у нас были данные из второй модели, мы могли бы попытаться отклонить первую модель (аналогично различению моделей с 3 отсеками и 2 отсеками в примерах ниже). другими словами,ds, вектор в диапазоне @xmath305 и @xmath306 для @xmath307 может находиться не только в диапазоне @xmath139 и @xmath140. далее мы рассмотрим эффект включения зависимостей коэффициентов. хотя мы не можем включить полиномиальные алгебраические зависимости между коэффициентами в наш линейно-алгебраический подход к отклонению модели, мы можем включить определенные условия зависимости, такие как то, что определенные коэффициенты становятся известными константами. мы уже видели один из способов, которым это может произойти в предыдущем примере (из известных ненулевых значений параметров). теперь мы исследуем случай, когда определенные коэффициенты стремятся к нулю. из явной формулы для уравнений ввода - вывода из @xcite мы получаем, что линейная модель без каких-либо утечек имеет нулевой член для коэффициента @xmath140. таким образом, линейная модель из 2 отсеков с одним входом и выходом в одном отсеке и соответствующая сильно связанному графу без каких-либо утечек имеет вид: @xmath308 таким образом, чтобы различать две различные линейные модели из 2 отсеков, одну с утечками и одну без каких-либо утечек, мы должны включить этот нулевой коэффициент в наш инвариант. рассмотрим следующие две линейные модели с 2 отсеками: @xmath309 @xmath310, соответствующие уравнения ввода - вывода которых имеют вид: @xmath311 в первой модели имеется утечка из первого отсека и обмен между отсеками @xmath144 и @xmath128. во второй модели происходит обмен между отсеками @xmath144 и @xmath128, и утечек нет. таким образом, наши инварианты можно записать следующим образом: @xmath312 опять же, правые части двух уравнений одинаковы, но первое уравнение имеет три переменные (коэффициенты), в то время как второе уравнение имеет две переменные (коэффициенты). таким образом, если бы у нас были данные из первой модели, мы могли бы попытаться отклонить вторую модель. другими словами, вектор в диапазоне @xmath305 и @xmath306 для @xmath307 может находиться не только в диапазоне @xmath139 и @xmath306. наконец, мы рассматриваем свойства идентифицируемости наших моделей. если количество параметров больше, чем количество коэффициентов, то модель неидентифицируема. с другой стороны, если количество параметров меньше или равно количеству коэффициентов, то модель, возможно, можно идентифицировать. очевидно, что идентифицируемая модель предпочтительнее неидентифицируемой модели. мы отмечаем, что в нашем подходе формирования линейной системы @xmath23 из уравнений ввода -вывода мы могли бы теоретически решить для коэффициентов @xmath22, а затем решить для параметров из этих известных значений коэффициентов, если модель идентифицируема @xcite. однако на практике это не является широко используемым методом оценки значений параметров. как отмечалось выше, возможные алгебраические зависимости между коэффициентами не учитываются в нашем подходе к линейной алгебре. это означает, что может существовать множество различных моделей с одной и той же дифференциальной полиномиальной формой уравнений ввода - вывода. если такая модель не может быть отвергнута, мы отмечаем, что идентифицируемая модель, удовлетворяющая определенному соотношению ввода-вывода, предпочтительнее неидентифицируемой, удовлетворяющей той же форме отношений ввода-вывода, как мы видим в следующем примере. рассмотрим следующие две линейные модели с 2 отсеками: @xmath299 @xmath313, соответствующие уравнения ввода - вывода которых имеют вид: @xmath314 в первой модели имеется утечка из первого отсека и обмен между отсеками @xmath144 и @xmath128. во второй модели имеются утечки из обоих отсеков и обмен между отсеками @xmath144 и @xmath128. таким образом, обе модели имеют инварианты вида : @xmath298 поскольку первая модель идентифицируема, а вторая модель неидентифицируема, мы предпочитаем использовать форму первой модели, если инвариант модели не может быть отклонен. после выполнения этого отклонения модели дифференциальной алгебраической статистики уже получены уравнения ввода - вывода для проверки структурной идентифицируемости @xcite. в некотором смысле, наш метод расширяет текущий спектр потенциальных подходов для сравнения моделей с данными о ходе времени, поскольку сначала можно отклонить несовместимые модели, затем проверить структурную идентифицируемость совместимых моделей, используя уравнения ввода-вывода, полученные в результате дифференциального исключения, вывести значения параметров допустимых моделей и применить информационный анализ. метод выбора критериальной модели для утверждения наилучшей модели. примечательно, что представленный метод дифференциальной алгебраической статистики не наказывает за сложность модели, в отличие от традиционных методов выбора модели. скорее, мы отклоняем, когда модель по каким-либо значениям параметров не может быть совместима с заданными данными. мы обнаружили, что более простые модели, такие как линейная модель с двумя отсеками, могут быть отклонены, когда данные были получены из более сложной модели, такой как модель Лотки - Вольтерры для трех видов, которая выявляет более широкий диапазон поведения. с другой стороны, более сложные модели, такие как модель Лоренца, часто не отвергались на основе данных, смоделированных из менее сложных моделей. в будущем было бы полезно лучше понять взаимосвязь между дифференциальными инвариантами и динамикой. мы также считаем, что было бы полезно исследовать алгебраические свойства sloppiness @xcite. мы считаем, что существует большой простор для дополнительных методов сравнения моделей копланарности без параметров. было бы полезно изучить, какие алгоритмы дифференциального исключения могут работать с более крупными системами, и можно ли расширить эту область. 

мы представляем метод отклонения конкурирующих моделей из зашумленных временных данных, который не основан на выводе параметров. сначала мы характеризуем модели обыкновенных дифференциальных уравнений только в измеримых переменных, используя исключение дифференциальной алгебры. затем мы извлекаем дополнительную информацию из приведенных данных, используя регрессию гауссовского процесса (gpr), а затем преобразуем дифференциальные инварианты. мы разрабатываем тест с использованием линейной алгебры и статистики, чтобы отклонять преобразованные модели с заданными данными без параметров. этот алгоритм использует информацию о переходных процессах, которая закодирована в структуре модели. мы демонстрируем мощь этого подхода, различая различные модели из математической биологии. ключевые слова: выбор модели, дифференциальная алгебра, алгебраическая статистика, математическая биология