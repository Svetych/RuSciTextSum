мы рассмотрим следующую модель пространства последовательностей @xmath4, где @xmath5 - коэффициенты сигнала, а шум @xmath6 имеет диагональную ковариационную матрицу @xmath7. эта гетерогенная модель может появиться в нескольких фреймворках, где дисперсия колеблется, например, в гетерогенной регрессии, цветном шуме, моделях дробного броуновского движения или обратных статистических задачах, для которых общая литература является довольно исчерпывающей. цель состоит в том, чтобы оценить неизвестный параметр @xmath8 с помощью наблюдений @xmath9. выбор модели является основной проблемой в статистике. одна из основных ссылок в этой области восходит к критерию aic @xcite, но на эту тему было опубликовано огромное количество статей (например, @xcite). выбор модели обычно связан с выбором штрафа, и его точный выбор является основной трудностью при выборе модели как с теоретической, так и с практической точки зрения. существует тесная взаимосвязь между выбором модели и процедурами установления пороговых значений, которая рассматривается, например, в @xcite. идея заключается в том, что поиск `хорошего штрафа\" при выборе модели действительно очень сильно связан с выбором `хорошего порога\" в вейвлет-процедурах. существует также интересная связь между контролем частоты ложных обнаружений (fdr) и пороговым значением и выбором модели, как описано в @xcite, что станет очевидным позже в нашей статье. наше основное предположение при моделировании заключается в том, что интересующий параметр @xmath3 является разреженным. разреженность является одной из ведущих парадигм в настоящее время, и сигналы с разреженным представлением в некотором базисе (например, вейвлеты) или функции с разреженными коэффициентами появляются во многих научных областях (см. @xcite среди многих других).    в этой статье мы рассматриваем модель пространства последовательностей с разнородными ошибками. затем наша цель состоит в том, чтобы выбрать из семейства моделей наилучшую из возможных, используя правило выбора, основанное на данных. в частности, приходится иметь дело с особой гетерогенной природой наблюдений, и выбор наказания должен отражать это. гетерогенный случай гораздо более сложный, чем прямая (однородная) модель. действительно, внутри стохастического процесса больше нет симметрии, которую нужно контролировать, поскольку каждый эмпирический коэффициент имеет свою собственную дисперсию. проблема и штраф зависят не только от количества выбранных коэффициентов, но и от их положения. это также проявляется в минимаксных границах, где коэффициенты в наименее благоприятной модели будут приводить к большим отклонениям. однако, благодаря тщательному и явному выбору штрафа, мы можем выбрать правильные коэффициенты и получить четкий неасимптотический контроль риска нашей процедуры. результаты также получены для полного выбора модели и управления типа fdr для семейства пороговых значений. в случае известной разреженности @xmath10 мы рассматриваем неадаптивную пороговую оценку и получаем минимаксную верхнюю границу. эта оценка точно достигает нижней границы и затем является минимаксной. используя наш подход к выбору модели, процедура почти минимаксна (с точностью до коэффициента 2). Более того, процедура полностью адаптивна. действительно, разреженность @xmath10 неизвестна, и мы получаем явное наказание, действительное в математических доказательствах и непосредственно применимое при моделировании. статья организована следующим образом. в следующем подразделе [ sec : exa ] мы приводим примеры проблем, в которых возникает наша гетерогенная модель. раздел [ sec : sel ] содержит процедуру, управляемую данными, и общий результат. в разделе [ sec: spa ] мы рассматриваем предположения о разреженности и получаем теоремы для процедур выбора полного подмножества и установления пороговых значений. разделы [ sec : low ] и [ sec : upp ] касаются минимаксных нижней и верхней границ. в разделе [ sec : num ] мы представляем численные результаты для свойств методов с конечной выборкой. рассмотрим сначала модель гетерогенной регрессии @xmath11, где @xmath12 являются стандартными гауссовыми, но их дисперсия колеблется в зависимости от расчетных точек @xmath13, а @xmath14 - это некоторая остроконечная неизвестная функция. в этой модели @xmath15. под функцией spiky мы подразумеваем, что @xmath16 равен нулю, за исключением небольшого подмножества всех расчетных точек @xmath13. эти сигналы часто встречаются в приложениях (хотя и редко моделируются в теоретической статистике), например, при измерении спектров поглощения в физической химии (т.е. редкие хорошо локализованные и сильные сигналы) или скачках логарифмической доходности цен на активы (т.е. логарифмические приращения цен, которые колеблются на низких уровнях, за исключением случаев, когда происходят более серьезные потрясения). часто в приложениях адекватными являются модели цветного шума. давайте рассмотрим здесь задачу оценки неизвестной функции, наблюдаемой с шумом, определяемым некоторым дробным броуновским движением, @xmath17,\\ ] ] где @xmath14 - неизвестная @xmath18периодическая функция в @xmath19, @xmath20=0, @xmath21 - уровень шума, а @xmath22 - дробное броуновское движение, определяется ( см. @xcite ), @xmath23, где @xmath24 - броуновское движение, @xmath25, @xmath26 - гамма-функция. дробное броуновское движение также появляется в эконометрических приложениях для моделирования явлений долговременной памяти, например, в @xcite. модель ( [ mod ] ) близка к стандартной модели гауссовского белого шума, которая соответствует случаю @xmath27. здесь поведение шума отличается. нас не интересует само дробное броуновское движение, но мы хотим оценить неизвестную функцию @xmath14 на основе зашумленных данных @xmath28, как в @xcite. очень важный момент связан с определением оператора дробного интегрирования. в этой структуре, если предполагается, что функция @xmath14 является @xmath18periodic, то естественным способом является рассмотрение периодической версии дробного интегрирования (приведенной в ( [ frac ] ) ), такой, что @xmath29 и, таким образом (см. стр.135 в @xcite), @xmath30 путем интегрирования и проецируя на основе косинуса (или синуса) и используя ( [ eigen ] ), можно получить модель пространства последовательностей (как в @xcite ), @xmath31, где @xmath32 независимы от @xmath33, где @xmath34 и @xmath35. рассмотрим следующую структуру общей обратной задачи @xmath36, где @xmath37 - известный инъективный компактный линейный ограниченный оператор, @ xmath14 - неизвестная @xmath38-мерная функция, @xmath39 - гауссовский белый шум и @xmath40 - уровень шума. мы будем использовать здесь структуру декомпозиции сингулярных значений (svd), смотрите, например, @xcite. обозначим через @xmath41 собственные функции оператора @xmath42, связанные со строго положительными собственными значениями @xmath43. обратите внимание, что любая функция @xmath14 может быть разложена в этом ортонормированном базисе как @xmath44, где @xmath45. пусть @xmath46 является нормализованной основой изображения @xmath47 путем проецирования и деления на сингулярные значения мы можем получить эмпирические коэффициенты @xmath48 затем мы получаем модель в пространстве последовательностей (см. @xcite ) @xmath49 с @xmath33 и @xmath50. мы рассматриваем модель пространства последовательностей для коэффициентов неизвестной @xmath51-функции @xmath14 относительно ортонормированной системы @xmath52. оценка по произвольному большому, но конечному набору индексов @xmath53 затем определяется с помощью @xmath54, где @xmath55 эмпирическая версия @xmath14 определяется как @xmath56 мы пишем @xmath57 и @xmath58 для мощности @xmath53. давайте запишем @xmath59 для ковариационной матрицы @xmath60, ограниченной индексами @xmath61, для которых @xmath62, т.е. @xmath63 с @xmath64. через @xmath65 мы обозначаем норму оператора, т.е. наибольшее абсолютное собственное значение.    случайные элементы @xmath66 принимают значения в пространстве выборок @xmath67. теперь мы рассмотрим произвольное семейство @xmath68 правил выбора подмножества, измеримых Борелем на основе управляемых данными. определите оценку, минимизировав в семействе @xmath69 наказуемый эмпирический риск : @xmath70 со штрафом @xmath71, где @xmath72 обозначает @xmath73-е по величине значение среди @xmath74 и @xmath75. обратите внимание, что @xmath76 определяется эквивалентным образом @xmath77, где @xmath78 затем определите оценку, основанную на данных @xmath79 следующая лемма показывает, что у человека есть явная оболочка риска, концепция, представленная полностью подробно в @xcite. [ th : hull ] функция @xmath80 со штрафом от является рискованной функцией, т.е. у нас есть @xmath81, напомним @xmath58 и введем стохастический термин @xmath82, заметим, что @xmath83 такой, что @xmath84 следует из @xmath85, давайте напишем @xmath86, и пусть @xmath87 обозначает обратный ранг @xmath88 в @xmath89 (например, @xmath90, если @xmath91 такой, что @xmath92 обратите внимание, что для любого перечисления @xmath93 из @xmath94 по монотонности : @xmath95 выполняется. таким образом, мы получаем со статистикой обратного порядка @xmath96 и @xmath97 (т.е. @xmath98 и т.д.) из @xmath99 и @xmath100, соответственно, @xmath101 { \\leqslant}\\operatorname{{\\mathbf e}}\\big[\\sum_{j=1}^n\\sigma_{(j)}^2\\big(\\zeta_{(j)}^2 - 2(\\log(ne / j)+j^{-1}\\log_+(n{\\lvert \\sigma \\rvert}))\\big)_+ \\big].\\ ] ] остается оценить @xmath102 $ ]. мы получаем по независимости, @xmath103 и неравенству коэффициента милля @xmath104 @xmath105, что означает для любого @xmath106 @xmath107=\\int_p ^\\infty p(\\zeta_{(j)}^2\u003e\\kappa)\\,d\\kappa{\\leqslant}2j^{-1}p^{-j/2}\\exp(j\\log(ne / j)-jp/2).\\ ] ] мы заключаем @xmath108\\ ] ] @xmath109 @xmath110, где @xmath111 и высший предел достигается при @xmath112 со значением @xmath113. [ th : oracle ] пусть @xmath76 - управляемое данными правило, определенное в ( [ hstar ] ). для любого @xmath114 у нас есть @xmath115+\\omega_\\delta,\\ ] ] где @xmath116 с учетом леммы [ th : hull ], @xmath117 - это оболочка риска, и, следовательно, у нас есть @xmath118, с другой стороны, поскольку @xmath76 минимизирует @xmath119, у нас есть @xmath120.\\ ] ] чтобы объединить неравенства ( [ ep1 ] ) и ( [ ep2 ] ), мы переписываем @xmath121 в терминах @xmath122 @xmath123, следовательно, используя это уравнение и ( [ ep1 ], [ep2 ] ), мы получаем @xmath124+{\\lvert f \\rvert}^2 + \\sqrt{2}\\min\\big(\\tfrac1n,{\\lvert \\sigma \\rvert}\\big ) + 2\\mathbf{e}_f \\, \\sum_{\\lambda \\in \\lambda } h_\\lambda^\\star f_\\lambda \\xi_\\lambda \\\\ & + \\mathbf{e}_f\\,\\biggl[\\sum_{\\lambda \\in \\lambda } h_\\lambda ^\\star \\xi_\\lambda^2-pen(h ^\\star)\\biggr ]. \\end{split}\\ ] ] теперь заметим, что для любого детерминированного набора индексов @xmath125 @xmath126 это означает, что для @xmath127 @xmath128 тогда, согласно общему неравенству @xmath129 для @xmath130 мы получаем @xmath131 обратите внимание, что @xmath132, поскольку @xmath133. с помощью ( [ cauch ] ) и ( [ vari_1 ] ) мы получаем @xmath134 аналогичным образом, мы получаем @xmath135 обратите внимание, что @xmath136, поскольку @xmath137. используя ( [ cauch2 ] ) и ( [ vari_2 ] ) у нас есть @xmath138 обратите также внимание, что, поскольку @xmath139, у нас есть @xmath140 вставка ( [ var - theta ] ) и ( [ var - theta2 ] ) в результаты @xmath141, используя оболочку риска, как в лемме [ th : hull ], получаем @xmath142 { \\leqslant}\\sqrt{2}\\min\\big(\\tfrac1n,{\\lvert \\sigma \\rvert}\\big).\\ ] ] вставка ( [ var - theta ] ), ( [ var - theta2 ] ) и ( [ hull2 ] ) в ( [ ep3 ] ) приводит к @xmath143+{\\lvert f \\rvert}^2 + \\sqrt{2}\\min\\big(\\tfrac1n,{\\lvert \\sigma \\rvert}\\big)+ \\tfrac{2}{\\delta}\\sum_{\\lambda \\in \\lambda}\\min(f_\\lambda^2,\\sigma^2_{\\lambda})\\\\ & \\quad + \\sqrt{2}\\min\\big(\\tfrac1n,{\\lvert \\sigma \\rvert}\\big)+ \\frac{\\delta}{2 } \\mathbf{e}_f\\|\\hat { f}(h ^\\star ) -f\\|^2.\\end{выровнено}\\ ] ] используя ( [ fin1 ] ), мы получаем, @xmath144 + 2\\sqrt{2}\\min\\big(\\tfrac1n,{\\lvert \\sigma \\rvert}\\big)+\\frac{2}{\\delta}\\sum_{\\lambda \\in \\lambda}\\min(f_\\лямбда^2,\\сигма^2_{\\лямбда}).\\ ] ] наконец, мы позволяем смещению явно отображаться в @xmath145, и результат следует из @xmath146 для @xmath147 $ ]. давайте рассмотрим интуитивную версию разреженности, предполагая небольшую долю ненулевых коэффициентов (см. @xcite), т.е. семейство @xmath148, где @xmath149 обозначает максимальная доля ненулевых коэффициентов.    повсюду мы предполагаем, что эта пропорция @xmath10 такова, что асимптотически @xmath150 цель здесь - изучить точность полного выбора модели по всему семейству оценок. каждый коэффициент может быть выбран как внутри модели, так и вне ее. давайте рассмотрим случай, когда @xmath151 обозначает все детерминированные выборки подмножеств, @xmath152 [ th : ms ] пусть @xmath76 - управляемое данными правило, определенное в ( [ hstar ] ) с @xmath151 как в ( [ hms ] ). мы имеем, для @ xmath153, равномерно по @ xmath154, в частности, @xmath155, если @xmath156 (т.е. допустимо любое многочленное увеличение для @xmath157) и @xmath158, тогда мы получаем @xmath159 для @xmath154 правая часть теоремы [ th : oracle ] может быть ограничена рассматривая оракул @xmath160 таким образом, что @xmath161+\\omega_\\delta & { \\leqslant}(1+\\delta)2pen(h ^ f)+\\omega_\\delta.\\end{выровнено}\\ ] ] мы будем использовать следующее неравенство, как @xmath162, @xmath163 для сравнения с интегралом. начиная с @xmath164, мы получаем, что @xmath165 @xmath166 как @xmath153. с другой стороны, у нас есть @xmath167, мы используем @xmath168, который показывает, что @xmath169 выбирает @xmath170 таким образом, что @xmath171, например, @xmath172, таким образом, мы находим, как @xmath173, @xmath174, используя теорему [ th : oracle ], уравнение ( [ omega_del ] ), у нас есть ( [ bound1 ] ). более того, используя границы для @xmath175 и @xmath157, мы получаем ( [ bound1b ] ). рассмотрим теперь семейство пороговых оценок. проблема заключается в изучении выбора порогового значения на основе данных. давайте рассмотрим случай, когда @xmath151 обозначает пороговые правила выбора с произвольными пороговыми значениями @xmath176 @xmath177 обратите внимание, что @xmath69 состоит только из @xmath58 различных правил выбора подмножеств и может быть эффективно реализован с использованием статистики порядка @xmath178. [ th : tr ] пусть @xmath76 - управляемые данными правила, определенные в ( [ hstar ] ) с @xmath151, как в ( [ htr ] ). если @xmath179, то мы имеем для @xmath153 равномерно по @xmath154 @xmath180, предполагая, что для @xmath181 границы роста @xmath182 с второе условие всегда проверяется, если @xmath183, это неравенство упрощается до @xmath184 давайте теперь оценим правую часть неравенства oracle в теореме [ th : oracle ] для правил выбора порога с произвольными пороговыми значениями @xmath176, определенными в ( [ htr ] ). учитывая параметр oracle @xmath185 (будет определено ниже ), мы устанавливаем @xmath186. мы получаем с помощью @xmath187, обозначающего (обратный) ранг коэффициента с индексом @xmath188 среди @xmath189 @xmath190\\\\ & { \\leqslant}\\mathbf{e}_f\\big [ \\sum_{\\lambda\\in\\lambda}\\big({\\bf 1}({\\lvert x_\\lambda \\rvert}{\\leqslant}\\tau_\\lambda)f_\\lambda^2- { \\bf 1}({\\lvert x_\\lambda \\rvert}\u003e\\tau_\\lambda ) ( x_\\lambda^2-f_\\lambda^2)\\\\ & \\qquad\\qquad + 4\\sigma_\\lambda^2 { \\bf 1}({\\lvert x_\\lambda \\rvert}\u003e\\tau_\\lambda)(\\log(en / r_\\lambda ) + r_\\lambda^{-1}\\log_+(n{\\lvert \\sigma \\rvert}))\\big)\\большой].\\end{выровнено}\\ ] ] давайте сначала покажем, что @xmath191 $ ] всегда неотрицательно. по симметрии @xmath192 подчиняется тому же закону, что и @xmath193. определяя функцию @xmath194, мы проверяем, рассматривая различные случаи, которые содержит @xmath195. мы заключаем @xmath196 & = \\tfrac12 \\имяоператора{{\\mathbf e}}_f[g(\\xi_\\лямбда)+g(-\\xi_\\лямбда)]{\\geqslant}0.\\end{выровнено}\\ ] ] следовательно, термин со знаком минус в может быть отброшенным за верхнюю границу. давайте теперь рассмотрим коэффициенты, которые содержат сигнальную часть (т.е. с @xmath197 ). следующее неравенство будет полезно для получения оценки, независимой от размера @xmath198. давайте обозначим через @xmath199 соответствующий обратный ранг внутри @xmath200. с помощью @xmath201 для события @xmath202 мы получаем @xmath203, где для последнего неравенства мы использовали, что для @xmath204 различных значений @xmath205 выражение максимально в случае @xmath206. общее тождество @xmath207=c+\\int_c^\\infty p(z{\\geqslant}z)dz$ ], примененное к @xmath208, и детерминированное @xmath209 дают @xmath210&{\\leqslant}c_\\lambda+\\int_{c_\\lambda}^\\infty p({\\lvert \\xi_\\lambda \\rvert}{\\geqslant}\\sqrt{z}-\\tau_\\лямбда)\\,dz { \\leqslant}c_\\лямбда+2e^{-(\\sqrt{c_\\лямбда}-\\tau_\\лямбда)^2/(2\\sigma_\\лямбда^2)}.\\end{выровнено}\\ ] ] чтобы гарантировать @xmath211 всякий раз, когда @xmath197, мы вынуждены выбирать @xmath212 в дальнейшем, мы связали @xmath213 просто с @xmath214 в случае @xmath197. затем, снова используя ограничение на суммы логарифмов ( [ sumlog ] ) и @xmath215, а также вогнутость @xmath216 для ограничения суммы экспонент, мы получаем, что по сигнальной части удовлетворяет @xmath217\\\\ & { \\leqslant}\\sum_{\\lambda\\in\\lambda, f_\\lambda\\not=0}(c_\\lambda+2e^{-(\\sqrt{c_\\lambda}-\\tau_\\lambda)^2/(2\\sigma_\\lambda^2 ) } ) { \\leqslant}n\\gamma_n(c_n{\\lvert \\sigma_{h_f } \\rvert}+2 e^{-(c_n-(t^0)^2)/2}),\\,\\ end{выровнено}\\ ] ] где @xmath218 благодаря @xmath219 у нас даже есть @xmath217 \\nonumber\\\\ & { \\leqslant}{\\lvert \\sigma_{h_f } \\rvert}n\\gamma_n c_n(1+o(1)).\\label{sig2}\\end{выровнено}\\ ] ] с другой стороны, для несигнальной части @xmath220 мы вводим @xmath221 и используем границу большого отклонения: @xmath222=n p({\\lvert \\xi_\\lambda \\rvert}\u003e\\tau_\\lambda){\\leqslant}2n(t^0)^{-1}e^{-(t^0)^2/2}. \\ ] ] снова рассматривая наихудшие перестановки вместо рангов, используя ( [ sumlog ] ) и неравенство Дженсена для вогнутых функций @ xmath223, мы выводим: @xmath224\\\\ & { \\leqslant}4{\\lvert \\sigma \\rvert}\\mathbf{e}_f\\left[\\sum_{\\lambda\\in\\lambda } { \\bf 1}({\\lvert \\xi_\\lambda \\rvert}\u003e\\tau\\lambda)(\\log(en / r_\\lambda)+r_\\lambda^{-1}\\log_+(n{\\lvert \\sigma \\rvert}))\\right]\\\\ & { \\leqslant}4{\\lvert \\sigma \\rvert}\\mathbf{e}\\left[\\sum_{j=1}^{n_\\tau}(\\log(en / j)+j^{-1}\\log_+(n{\\lvert \\sigma \\rvert}))\\right]\\\\ & { \\leqslant}4{\\lvert \\sigma \\rvert}\\mathbf{e}\\left[(n_\\tau\\log(en / n_\\tau)+\\log(n_\\tau)\\log_+(n{\\lvert \\sigma \\rvert}))\\right ] ( 1+o(1))\\\\ & { \\leqslant}4{\\lvert \\sigma \\rvert } ( 2n ( t^0)^{-1 } e^{-(t^0)^2/2}(1+t_0 ^ 2/2)+(\\log n-(t^0)^2/2)\\log_+(n{\\lvert \\sigma \\rvert}))(1+o(1))\\\\ & { \\leqslant}2{\\lvert \\sigma \\rvert}(2n e^{-(t^0)^2/2}t^0+(2\\log n-(t^0)^2)\\log_+(n{\\lvert \\sigma \\rvert}))(1+o(1)).\\end{выровнено}\\ ] ] для выбранного @xmath225 общая граница, таким образом, равна ( [ sig2 ] ), ( [ eq42 ] ) и по определению @xmath226 в ( [ c_n ] ), @xmath227 это приводит к утвержденной общей границе и вставке привязка для @xmath228 дает непосредственно вторую привязку.      _ гетерогенный случай. _ можно сравнить метод и его точность с другими результатами в связанных фреймворках. например, @xcite рассматривает очень близкие рамки выбора модели в обратных задачах, используя подход svd. это приводит к появлению шума @xmath229, который является неоднородным и диагональным. @xcite изучите соответствующую тему обратных задач и вейвлет-декомпозиции (wvd), построенную на @xcite. структура в @xcite более общая, чем у нас. однако это приводит к менее точным результатам. во всех их результатах @xcite существуют универсальные константы, которые на самом деле не контролируются. это еще более важно для констант внутри метода, например, в штрафе. наш метод содержит явное ограничение. он используется в математических результатах, а также в моделировании без дополнительной настройки. возможное расширение нашего метода на зависимый случай wvd не кажется прямолинейным. _ однородный случай. _ давайте сравним с другой работой для однородной настройки @xmath230. в этой структуре существует множество результатов, см., например, @xcite. опять же, эти результаты содержат универсальные константы не только в математических результатах, но даже внутри методов. например, константы перед штрафом, но также и внутри метода fdr, с гиперпараметром @xmath231, который необходимо настроить. возможно, наиболее близкой к нашей работе статьей является @xcite в однородном случае. наш штраф аналогичен штрафу `вдвое превышающему оптимальный\", рассмотренному в @xcite. это связано с трудностями в гетерогенном случае, когда стохастический процесс, который нужно контролировать, гораздо более вовлечен в эту настройку. действительно, в этом стохастическом процессе больше нет симметрии, поскольку каждый эмпирический коэффициент имеет свою собственную дисперсию. проблема и штраф зависят не только от количества выбранных коэффициентов, но и от их положения. это приводит к результату @xmath232, где мы получаем константу @xmath233 в @xcite. потенциальная потеря factor 2 в гетерогенной структуре теоретически можно было бы избежать, но при моделировании результаты кажутся сравнительно менее чувствительными к этому фактору, чем к другим модификациям, например, к тому, сколько точек данных среди ненулевых коэффициентов @xmath204 близки к критическому пороговому уровню, который определяет какой-либо эффективный разреженность проблемы (часто меньше, чем @xmath204). этот эффект не рассматривается в теоретической установке во всех исследованиях, связанных с fdr, где подразумевается наихудший сценарий величины коэффициентов. [ th : lower ] для любой оценки @xmath234, основанной на наблюдениях @xmath235, у нас есть минимаксная нижняя граница @xmath236 { \\geqslant}\\sup_{\\alpha_n\\in s_\\lambda(n\\gamma_n, c_n ) } 2\\big(1+o(1)\\big)\\big(\\sum_{\\lambda\\in\\lambda } \\sigma_\\lambda ^2\\alpha_{\\lambda, n}\\log(\\alpha_{\\lambda, n}^{-1})\\big)\\ ] ] для некоторого @xmath237, где @xmath238^\\lambda\\,|\\,\\sum_\\lambda\\alpha_\\lambda{\\leqslant}r(1-c)\\}$ ] обозначает пересечение @xmath239, умноженное на @xmath235-мерный единичный куб, с @xmath240, умноженное на @xmath235-симплекс, и где @xmath241 как @xmath153.    равномерное распределение массы по индексам @xmath242 с наибольшими значениями @xmath243 дает нижнюю границу, как @xmath153, @xmath236 { \\geqslant}2n\\gamma_n\\log(\\gamma_n^{-1})\\big(1+o(1)\\big)\\frac 1{r_n}\\sum_{i=1}^{r_n } \\sigma_{(i ) } ^2\\ ] ] в терминах статистики обратного порядка @xmath244, предоставленной @xmath245 (т.е. @xmath242 должно быть несколько больше, чем @xmath204). Обратите внимание, что для полиномиального роста @xmath246, @xmath247, нижняя граница, как @xmath153, @xmath236 { \\geqslant}2\\big(1+o(1)\\big){\\lvert \\sigma \\rvert}n\\gamma_n\\log(\\gamma_n^{-1}).\\ ] ] нижняя граница является своего рода взвешенная энтропия. в отличие от верхних границ над минимаксной (и байесовской) нижней границей не используется величина @xmath214, индивидуальная для каждого неизвестного @xmath14. в доказательстве для этой гетерогенной модели концептуально нам нужно учитывать высокую сложность класса @xmath248, что приводит к коэффициенту энтропии @xmath249, и использовать большую априорную вероятность для коэффициентов с большей дисперсией, что объясняет абстрактное взвешенное выражение энтропии. рассмотрим для каждого коэффициента @xmath250 следующий байесовский априор, который оказывается асимптотически наименее благоприятным: @xmath251 с некоторым @xmath252. без потери общности мы можем предположить, что @xmath253 так медленно, что @xmath254. вводя число ненулевых записей @xmath255 и записывая @xmath256 для совместного закона предшествования и наблюдений, мы выводим с помощью неравенства Чебышева @xmath257 свойство @xmath258 затем подразумевает, что байесовский оптимальный риск, полученный ниже, будет асимптотической минимаксной нижней границей над @xmath248. нам нужно рассчитать байесовский риск и найти апостериорный закон @xmath259 для каждой координаты @xmath61 : @xmath260 поскольку мы имеем дело с квадратичными потерями, байесовская оценка @xmath261 равна условному математическому ожиданию @xmath262 $ ], а байесовский риск - математическому ожиданию условной дисперсии, которая вычисляется как @xmath263=\\имяоператора{{\\mathbf e}}[f_\\лямбда ^2]-\\имяоператора{{\\mathbf e}}[\\имяоператора{{\\mathbf e}}[f_\\лямбда |x_\\лямбда ] ^2 ] = \\mu_{\\лямбда, n}^2\\big(\\alpha_{\\lambda, n}-\\int \\frac{\\alpha_{\\lambda, n}^2{\\varphi}_{\\mu_{\\lambda, n},\\sigma_\\lambda ^2}(x)^2 } { ( 1-\\alpha_{\\lambda, n}){\\varphi}_{0,\\sigma_\\lambda ^2}(x)+ \\alpha_{\\lambda, n}{\\varphi}_{\\mu_{\\lambda, n},\\sigma_\\lambda ^2}(x)}\\,dx\\большой).\\ ] ] интеграл может быть преобразован в математическое ожидание относительно @xmath264 и ограничен неравенством Дженсена: @xmath265\\\\ & \\qquad { \\leqslant}\\alpha_{\\лямбда, n } \\big(1+\\alpha_{\\лямбда, n}^{-1}(1-\\alpha_{\\lambda, n})\\имяоператора{{\\mathbf e}}[\\exp(\\sigma_\\lambda ^{-1}z-\\mu_{\\lambda, n}^2/(2\\sigma_\\lambda ^2))]\\big)^{-1 } \\\\ & \\qquad = \\alpha_{\\лямбда, n } \\big(1+\\alpha_{\\лямбда, n}^{-1}(1-\\alpha_{\\лямбда, n})\\exp((1-\\mu_{\\лямбда, n}^2)/(2\\sigma_\\lambda ^2))\\big)^{-1}.\\end{выровнено}\\ ] ] поскольку @xmath266 равномерно, мы просто выбираем @xmath267 таким образом, что @xmath263{\\geqslant}2\\sigma_\\lambda ^2\\alpha_{\\lambda, n}(1-(\\log c_n^{-1})^{-1/2})\\ log(\\alpha_{\\лямбда, n}^{-1 } ) ( 1-((1+(1-\\ alpha_{\\лямбда, n})\\alpha_{\\лямбда, n}^{-(\\log c_n^{-1})^{-1/2}} e^{1/(2\\sigma_\\lambda ^2)}))^{-1}).\\ ] ] отмечая, что @xmath268 равномерно превосходит @xmath188, общий байесовский следовательно, риск равномерно ниже, ограниченный @xmath269, максимальный уровень в @xmath235 достигается для @xmath270, где @xmath271 таков, что @xmath272 выполняется, при условии @xmath273 для всех @xmath188. последнее условие выполняется, если @xmath274. в качестве альтернативы, мы можем написать @xmath275, и выражение энтропии станет @xmath276, где @xmath277 $ ] суммируется до единицы : @xmath278. из этого представления мы немедленно выводим нижнюю границу @xmath279, используя равномерные веса @xmath280. обратите внимание, что для полиномиального роста @xmath246, @xmath247 и для @xmath281 у нас есть @xmath282, и нижняя граница действительно равна @xmath236 { \\geqslant}2\\big(1+o(1)\\big){\\lvert \\sigma \\rvert}n\\gamma_n\\log(\\gamma_n^{-1}).\\ ] ] рассмотрим теперь настройку, в которой известна разреженность @xmath10 и применяется правильно настроенная пороговая оценка, чтобы идентифицировать неизвестные положения значимых ненулевых коэффициентов @xmath283. [ th : upper ] рассмотрим пороговую оценку, определенную по координатам @xmath284 и @xmath285, выбранную таким образом, что @xmath286. тогда, как @xmath153, @xmath236{\\leqslant}2n\\gamma_n\\beta_n(1+o(1))\\ ] ] выполняется. это подразумевает, что, как @xmath153, @xmath236{\\leqslant}2n\\gamma_n\\log(\\gamma_n^{-1}){\\lvert \\sigma \\rvert}(1+o(1)),\\ ] ], который является минимаксно оптимальным не более чем для полиномиального роста в @xmath287 на нижняя граница в теореме [ th : нижняя ].    для более быстрого роста, чем полиномиальный, мы вполне могли бы иметь @xmath288. таким образом, в целом верхняя граница точно соответствует нижней границе по отношению к члену @xmath289, в то время как влияние гетерогенного шума зависит от конкретного случая. однако эта процедура неадаптивна, поскольку пороговое значение зависит от знания разреженности @xmath10.    введите пороговое значение @xmath290 и обратите внимание на @xmath291. мы можем разделить ошибку следующим образом: @xmath292=f_\\lambda^2\\operatorname{{\\mathbb p}}((\\xi_\\lambda+f_\\lambda/\\sigma_\\lambda)^2{\\leqslant}\\tau_{\\lambda, n}^2)+\\имя оператора{{\\mathbf e}}[\\sigma_\\lambda ^2\\xi_\\lambda^2{\\bf 1}_{\\{(\\xi_\\lambda+f_\\lambda/\\sigma_\\lambda)^2\u003e\\tau_{\\lambda, n}^2\\}}] =:i+ii.\\ ] ] для @xmath293 член i оценивается @xmath294 вместе с симметричным аргументом для @xmath295 и прямой оценкой для @xmath296, таким образом, мы получаем оценку для общего @xmath283 : @xmath297 поскольку для @xmath298 у нас есть @xmath299, мы рассматриваем @xmath300 и выводим @xmath301, вводя выбор пороговых значений, мы заключаем, что @xmath302 для члена ii и @xmath197 достаточно немедленной оценки @xmath303, в то время как для @xmath220 мы явно интегрируем и получаем: @xmath304=\\sigma_\\lambda^22(\\tau_{\\lambda, n}+1)e^{-\\tau_{\\лямбда, n}^2/2 } = 2\\sigma_\\лямбда^2\\sqrt{2\\log(\\alpha_{\\лямбда, n}^{-1})}\\alpha_{\\лямбда, n}(1+\\tau_{\\лямбда, n}^{-1}).\\ ] ] таким образом, общий риск нашей оценки ограничен @xmath305{\\leqslant}\\sum_{\\lambda : f_\\lambda\\not=0}\\big(2\\sigma_\\lambda^2\\log(\\alpha_{\\lambda, n}^{-1})(1+o(1 ) ) + \\sigma_\\lambda^2\\big)+\\sum_{\\lambda : f_\\lambda=0 } 2\\sigma_\\lambda^2\\sqrt{2\\log(\\alpha_{\\lambda, n}^{-1})}\\alpha_{\\lambda, n}(1+o(1))\\\\ & { \\leqslant}(2+o(1 ) ) \\big(\\sum_{\\lambda : f_\\lambda\\not=0}\\log(\\alpha_{\\лямбда, n}^{-1})\\sigma_\\лямбда^2 + \\sqrt 2\\max_\\лямбда\\big((\\log(\\alpha_{\\лямбда, n}^{-1}))^{-1/2}\\ alpha_{\\лямбда, n}\\big)\\sum_{\\lambda : f_\\lambda=0 } \\sigma_\\lambda^2\\log(\\alpha_{\\lambda, n}^{-1})\\big).\\end{выровнено}\\ ] ] выбор @xmath306 с @xmath285, удовлетворяющим @xmath286, минимизирует последнюю границу (асимптотически) и дает @xmath307{\\leqslant}(2+o(1))n\\gamma_n\\beta_n\\ ] ], потому что по @xmath308 второй член имеет меньший размер порядок. последний результат является прямым следствием. действительно, мы всегда имеем @xmath309, ограничивая @xmath310, который является минимаксно оптимальным для максимального полиномиального роста в @xmath287 по нижней границе в теореме [ th : lower ]. (синий ), наблюдения @xmath311 ( зеленый в полном подмножестве, зеленый / желтый в адаптивном пороге, пурпурный не учитывается ) и универсальные / разреженные пороги ( черный ) (значения параметров : @xmath312, @xmath313, @xmath314 для @xmath315 )., ширина=529, высота=264 ] на рисунке [ рис. 1 ] типичная реализация коэффициентов @xmath283 показана синим цветом с 50 ненулевыми коэффициентами, выбранными равномерно на @xmath316 $ ] и увеличивающимся уровнем шума @xmath314 для @xmath317. внутренние черные диагональные линии указывают на порог разреженности (со значением oracle @xmath10 ), а внешние диагональные линии - на универсальный порог. не синие точки отображают зашумленные наблюдения @xmath193. наблюдения, включенные в адаптивную оценку выбора полного подмножества, окрашены в зеленый цвет, в то время как наблюдения, включенные в адаптивную пороговую оценку, представляют собой объединение зеленых и желтых точек (фактически, для этой выборки адаптивная пороговая обработка выбирает все выбранные точки полного подмножества), отброшенные наблюдения выполнены пурпурным цветом.        мы провели 1000 экспериментов по методу Монте-карло для параметров @xmath312, @xmath314 в разреженном (@xmath318) и плотном (@xmath313) случае. на рисунке [рис. 2 ] показаны первые 100 относительных ошибок для различных процедур оценки в плотном случае. ошибки взяты как частное от выборочного порогового значения oracle, примененного к перенормированному @xmath319. следовательно, только при выборе полного подмножества относительные ошибки иногда могут быть меньше единицы. в таблице [ tab1 ] перечислены относительные ошибки монте-карло для двух случаев. в последнем столбце сообщается об относительной ошибке процедуры oracle с помощью @xmath320, которая отбрасывает все наблюдения @xmath193 с помощью @xmath220 (не обращая внимания на сложность выбора модели). результаты моделирования довольно стабильны при различных настройках. в целом, пороговое значение работает глобально хорошо. (приблизительная) процедура выбора полного подмножества (смотрите ниже жадный алгоритмиспользуемый ithm ) немного хуже и демонстрирует более высокую вариабельность, но все равно довольно хорош. по конструкции, в плотном случае oracle sparse threshold работает лучше, чем universal threshold, в то время как universal threshold работает лучше в очень разреженных ситуациях. причина, по которой разреженный порог даже при теоретическом выборе oracle @xmath10 не работает так хорошо, заключается в том, что весь теоретический анализ основан на потенциально наиболее сложных соотношениях сигнал/шум, то есть коэффициентах @xmath283 размера порога или уровня шума. здесь, однако, эффективная разреженность больше (т.е. эффективная @xmath10 меньше), потому что равномерно сгенерированные ненулевые коэффициенты могут быть относительно небольшими, особенно для индексов с высоким уровнем шума, см. также рисунок [ рис. 1 ]. Давайте кратко опишем, как была реализована процедура адаптивного выбора полного подмножества. формула приписывает каждому выбранному коэффициенту @xmath193 индивидуальный штраф @xmath321 с обратным рангом @xmath322 от @xmath323. благодаря @xmath324 все коэффициенты с @xmath325 включаются в @xmath326 на начальном этапе. затем итеративно @xmath327 расширяется до @xmath328 путем включения всех коэффициентов с помощью @xmath329 итерация останавливается, когда дополнительные коэффициенты не могут быть включены. оценщик @xmath330 на этом этапе определенно содержит все коэффициенты, также взятые @xmath331. на второй итерации мы теперь добавляем более жадным способом коэффициенты, которые уменьшат общий оштрафованный эмпирический риск. включение нового коэффициента @xmath332 добавляет к оштрафованному эмпирическому риску (положительное или отрицательное) значение @xmath333 здесь @xmath334 следует понимать как ранг в @xmath335 при установке @xmath336. следовательно, вторая итерация расширяет @xmath330 каждый раз на один коэффициент @xmath332, для которого отображаемое значение формула дает отрицательное значение до тех пор, пока не будет достигнуто дальнейшее снижение общего оштрафованного эмпирического риска. эта вторая жадная оптимизация не обязательно приводит к оптимальному решению для выбора полного подмножества, но чаще всего на практике она приводит к выбору коэффициента @xmath331 со значительно меньшим штрафным эмпирическим риском, чем процедура адаптивного порога. численная сложность алгоритма составляет порядка @xmath337 из-за второй итерации, в отличие от экспоненциального порядка @xmath338 при сканировании всех возможных подмножеств. более точный анализ нашей процедуры был бы интересен, но может иметь незначительное статистическое влияние ввиду хороших результатов для прямолинейной адаптивной схемы установления пороговых значений. 

мы рассматриваем модель пространства гауссовых последовательностей @xmath0, где @xmath1 имеет диагональную ковариационную матрицу @xmath2. мы рассматриваем ситуацию, когда вектор параметров @xmath3 разрежен. наша цель - оценить неизвестный параметр с помощью подхода к выбору модели. гетерогенный случай гораздо сложнее, чем прямая модель. действительно, внутри стохастического процесса больше нет симметрии, которую нужно контролировать, поскольку каждый эмпирический коэффициент имеет свою собственную дисперсию. проблема и штраф зависят не только от количества выбранных коэффициентов, но и от их положения. это проявляется также в минимаксных границах, где худшие коэффициенты будут соответствовать большим отклонениям. однако при тщательном и явном выборе штрафа мы можем выбрать правильные коэффициенты и получить четкий неасимптотический контроль риска нашей процедуры. приведены некоторые результаты моделирования.