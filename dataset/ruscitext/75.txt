ОПРЕДЕЛЕНИЕ СЕМАНТИЧЕСКОЙ БЛИЗОСТИ РУССКОЯЗЫЧНЫХ ТЕКСТОВ С ИСПОЛЬЗОВАНИЕМ ИНСТРУМЕНТА DKPRO SIMILARITY

 1. Введение 
Оценка семантической близости текстов является неотъемлемой составляющей многих задач современной компьютерной лингвистики, среди которых создание и функционирование информационно-поисковых систем, вопросно-ответных систем, систем автоматического реферирования, классификации текстов, определения тематики текстов, перефразирования, разрешения лексической неоднозначности и др. До сих пор разработка и тестирование алгоритмов и метрик для оценки семантической близости текстов проводились в основном применительно к материалу английского языка. Это можно проиллюстрировать классом компьютерных инструментов, созданных для решения данной задачи: ср. WordNet::Similarity1, Alchemy API2 и ряд других. Об успехах в этой области также свидетельствуют результаты соревнований SemEval3 на специальной дорожке Semantic Textual Similarity. Необходимость подобных исследований для русского языка обусловлена востребованностью ожидаемых результатов в компьютерной лингвистике. В частности, метрики семантической близости текстов и определение семантических отношений между словами могут использоваться при создании инструментов автоматического понимания текстов.
В настоящий момент есть прогресс в области автоматической оценки семантической близости на уровне слов (см. данные RUSSE4 [1]), однако задача определения близости текстов не подвергалась тщательному изучению: акцент делается не на количественных данных о схожести текстов, а на результатах кластеризации или классификации большого числа документов в корпусе (например, когда нужно определить тематику корпуса или назначить рубрики для отдельных его сегментов). Наше исследование призвано восполнить существующий пробел.
Итак, в данной работе мы решаем задачу оценки семантической близости текстов на русском языке средствами открытой и свободно распространяемой компьютерной платформы DKPro Similarity, что предполагает изучение возможностей данной платформы, адаптацию инструмента для работы с русским языком, эксперименты на текстовом материале с использованием различных метрик семантической близости.
2. Компьютерный инструмент DKPro Similarity
Компьютерный инструмент DKPro Similarity5 разработан в Дармштадском Технологическом Университете (TU Darmstadt)6 исследовательской группой [2]. Эта платформа была создана как дополнение DKPro Core, набора компонентов ПО для обработки естественного языка; инструмент поддерживается на языках Java, Jython и Groovy. Преимуществами данной платформы являются ее открытый характер, реализация множества существующих метрик близости текстов с использованием стандартизованного способа их вызова, а также возможность разрабатывать собственные метрики на основе уже существующих. DKPro Similarity включает в себя различные классы метрик близости текстов: структурные, стилистические, строковые, семантические и фонетические. В нашем исследовании мы опираемся на строковые метрики, не зависящие от языка обрабатываемого текста.
3. Лингвистические данные
Мы сформировали экспериментальную выборку текстов таким образом, что в нее вошли тексты, результаты вычисления близости которых можно было адекватно оценить (подробнее об этом см. раздел 4.2), так как для русского языка нет «золотого стандарта» для оценки семантической близости текстов, т.е. корпуса, в котором пары текстов были бы снабжены экспертными оценками их сходства8. Таким образом, материалом исследования послужили следующие группы текстов: аннотации научных статей из корпуса по корпусной лингвистике кафедры математической лингвистики СПбГУ; сообщения из сегментов «life» и «news» новостного корпуса кафедры математической лингвистики СПбГУ; три перевода на русский язык романа В. Набокова «Пнин» (а именно, переводы Г. А. Барабтарло, С. Б. Ильина, Б. М. Носика); заголовки новостных статей из корпуса парафразов в проекте ParaPhraser.ru9.
Из каждой группы случайным образом было выбрано несколько текстов для дальнейшей работы: пять аннотаций; по пять сообщений из двух частей новостного корпуса; пять соответствующих друг другу отрывков из трех переводов; а также по пять пар парафразов из каждой группы в корпусе (преимуществом является то, что в этом корпусе каждой паре предложений соответствует экспертная оценка того, в какой мере они действительно являются парафразами: «-1» – предложения на разные темы, «0» – предложения на одну тему, но есть изменения смысла, «1» – абсолютные парафразы). Приведем информацию о длине используемых текстов (см. Таблицу 1).
Перед вычислением семантической близости текстов была проведена их обработка: удаление знаков препинания и лемматизация с использованием библиотеки PyMorphy210 [3].
4. Ход экспериментов
4.1 Используемые метрики семантической близости текстов
В DKPro Similarity реализовано более 15 различных строковых метрик близости, из которых в нашем исследовании мы использовали семь наиболее обсуждаемых, ср. [4], [5], [6], [7].
Следует отметить, что значение всех из них принадлежит отрезку [0,1], кроме расстояния Левенштейна, которое, наоборот, равно нулю, если два текста идентичны, и тем больше, чем больше в них различий в символах, причем это число ограничено сверху только длиной большего текста. Также важной деталью является то, что значение двух из данных метрик – Word N-Gram Containment Measure и Greedy String Tiling – зависит от порядка, в котором документы сравниваются друг с другом: в знаменателе формулы стоит число, связанное только с одним из текстов (количество n-грамм в первом документе и длина второго документа соответственно). В связи с этим при использовании этих метрик мы вычисляли оба значения.
Для текстов из каждой группы (см. раздел 3) было вычислено девять значений близости, в результате чего мы получили несколько таблиц с результатами: пять для каждой группы текстов и одну, в которой сравнивались тексты из разных групп. В Таблице 2 можно увидеть, как выглядели значения всех метрик близости для сравнений нескольких пар аннотаций. 
4.2 Оценка результатов близости текстов
Как мы уже говорили, «золотого стандарта» для задачи определения схожести текстов на русском языке не существует, поэтому мы выработали собственные способы оценки полученных результатов. Напомним, что в корпусе парафразов предложения уже были оценены вручную (см. раздел 3). Мы решили следовать такому же методу, но он подходит только для текстов, которые изначально близки друг к другу: из наших материалов этому параметру соответствуют отрывки переводов романа «Пнин». Каждый из них мы разбили на небольшие фрагменты (по одному-двум предложениям), соответствующие друг другу в разных переводах. В результате каждый из пяти изначальных отрывков был представлен несколькими текстовыми документами, в которых находилось три маленьких отрывка. Был проведен эксперимент с участием информантов – экспертов (студентов кафедры математической лингвистики). Мы попросили их оценить попарное сходство фрагментов. Семантическая близость целостных текстов определялась через средние оценки близости их отрывков. Каждое значение оценивалось двумя участниками, и сравнение проводилось отдельно по двум критериям:
1. Смысловой критерий: насколько тексты похожи по смыслу (используется шкала «0-1-2», где «2» - сильная степень схожести, «1» - средняя степень, «0» - небольшая степень схожести);
2. Формальный критерий: насколько близость текстов определяется входящими в их состав словами (также используется шкала «0-1-2», но при оценке предлагалось учитывать критерии, схожие с критериями автоматического распознавания парафраз в проекте ParaPhraser.ru): а) наличие одинаковых слов; б) наличие синонимов / транспозиции / общих корней.
В результате для каждой пары сравниваемых текстов было получено два значения от «0» до «2»: одно выражает близость текстов со смысловой точки зрения, другое – с формальной, и именно они использовались в машинном обучении (см. раздел 4.3). Для оценки согласованности ответов участников эксперимента мы использовали взвешенную Каппу Коэна (Weighted Cohen’s Kappa), присваивая вес 0,1 неодинаковым ответам, отличающимся друг от друга на единицу (то есть оценкам «0» и «1» или «1» и «2»), и вес 10 – тем случаям, когда участники поставили оценки «0» и «2» одному отрывку. Показатель согласованности оказался равен 0,68.
Однако для других текстов из экспериментальной выборки подобный критерий не применим, так как они изначально не объединены общей темой. Поэтому мы следовали следующей стратегии: исходя из того, что тексты из одной группы похожи друг на друга больше, чем на тексты из других групп, каждой паре документов мы поставили оценку «1», если они принадлежат одной группе, и «0», если они относятся к разным. После этого шага количество наборов данных увеличилось.
a) Результаты для текстов из корпуса новостей были разделены на три набора: два, состоящих из значений близости текстов внутри подгрупп «news» и «life» отдельно, и один, включающий сравнения текстов как внутри этих подгрупп, так и между собой;
b) Из группы с текстами романа «Пнин» было так же составлено два набора: один включает только сравнения переводов одинаковых фрагментов, другой – сравнения любых текстов из романа;
Эти разделения обусловлены тем, рассматриваем ли мы все тексты из корпуса новостей или романа «Пнин» как относящиеся к одной группе или к разным.
c) Также мы создали еще один набор данных, в котором близость парафраз оценивалась бинарно: «0», если в корпусе стояло значение «-1», т.е. если предложения друг с другом никак не связаны, и «1», если в корпусе были указаны оценки «0» или «1».
4.3 Обучение
На данном этапе у нас было одиннадцать наборов данных, объектами в которых выступали пары текстов, а их признаками – значения мер близости. К признакам мы также добавили длину обоих текстов, так как от них зависит значение некоторых метрик (см. раздел 4.1). Таким образом, каждый объект характеризовался одиннадцатью признаками, а также эталонным значением: для семи датасетов это было значение «1» (см. Таблицу 3), для одного (не-бинарной оценки парафраз) – «-1», «0» или «1», для двух (смысловой и формальной близости отрывков из романа «Пнин») – вещественное значение от 0 до 2, и для одного (текстов из разных групп) – значение «0». Каждый датасет со значением целевого признака «1» был объединен с датасетом с «0», значения признаков отмасштабированы.
В результате каждый набор данных состоял в среднем из 35 объектов. Так как для оценки результатов мы используем трехкратную кросс-валидацию, каждый раз объем обучающей выборки составлял примерно 66% (23 объекта), а тестовой, соответственно, 33% (12 объектов). Машинное обучение производилось на языке программирования «Python», с использованием библиотеки scikitlearn12. В ней можно найти реализацию методов, о которых речь пойдет дальше.
Для задач классификации эксперименты проводились с несколькими линейными моделями: Logistic Regression, Ridge Classifier, SGD Classifier, Passive Aggressive Classifier, Perceptron. В результате для каждого набора данных выбиралась одна модель, показавшая наилучший результат при трехкратной кросс-валидации с оценкой результатов по F-мере (см. Таблицу 4). Поясним некоторые обозначения в таблице. Если название метода не снабжено дополнительными комментариями, использовалась его реализация с параметрами по умолчанию. «Grid Search» - подбор наилучшей комбинации параметров из предложенных пользователем. «L1 regression» - это использование L1регуляризации (регуляризации Лассо) вместо L2-регуляризации, которая применяется по умолчанию
Для двух задач, где ответом должно было быть вещественное число (датасеты с проставленной вручную оценкой близости фрагментов из романа «Пнин»), также использовались линейные модели, но они не показали точных результатов. Меньших значений средней абсолютной ошибки (mean absolute error) удалось достичь, используя Random Forest Regressor: для оценок по смыслу ошибка оказалась равна 0,208, а для формальных оценок – 0,188.
4.4 Выводы
Как мы видим, классификаторы, обученные даже на таких простых признаках, как значения строковых метрик близости текстов, показывают неплохие результаты. В связи с этим мы предлагаем использовать веса, назначенные признакам линейными моделями, в качестве способа оценки строковых метрик для конкретной задачи. Для этой цели была составлена таблица со значениями весов лучших моделей (см. Таблицу 5: в ней выделены наибольшие веса для каждого датасета).
Для каждой метрики мы вычислили среднее значение весов по модулю (при этом мы не учитывали веса для датасетов «All News» и «All Pnin»13, так как из-за использования регуляризации Лассо (L1) многие признаки имеют нулевой вес, а другие, наоборот, значительно бóльшие веса по сравнению с остальными). Вычисления показали, что наибольшие веса у N-Gram Containment Measure и Cosine Similarity. Таким образом, именно они наиболее подходят для поставленной задачи. 
5. Заключение
Итак, мы показали, что даже строковые метрики оценки близости текстов, которые, как обычно считается, дают хорошие результаты только для очень схожих по наборам слов текстов, в данном случае позволяют линейным моделям достаточно хорошо работать при классификации текстов. В дальнейшем также планируется провести эксперименты с семантическими метриками близости, опирающимися на внешние источники знаний (например, на «Википедию»: см. ESA [14]), и сравнить результаты, которые будут получены, с результатами данного исследования. Также планируется расширить языковой материал и, возможно, использовать более сложные модели машинного обучения для получения лучших результатов.

В статье рассказывается о том, что оценка семантической близости текстов является неотъемлемой составляющей многих задач современной компьютерной лингвистики. Однако, до сих пор разработка и тестирование алгоритмов и метрик для оценки семантической близости текстов проводились в основном применительно к материалу английского языка. В работе рассматривается проблема оценки семантической близости текстов на русском языке. Описываются преимущества использования открытой компьютерной платформы DKPro Similarity для решения этой проблемы, сосредоточив внимание на строковых метриках оценки близости текстов. Эксперименты проводятся на материале тестовой выборки, включающей сходные фрагменты художественных, научных и новостных текстов. Показано, что применяя алгоритмы машинного обучения и оперируя полученными значениями близости текстов, простые строковые метрики позволяют достичь высоких результатов при определении отнесенности текстов к одной группе с помощью линейных моделей. В исследовании предлагается метод оценки релевантности метрик для конкретных задач. В заключении показано, что даже строковые метрики оценки близости текстов, которые, как обычно считается, дают хорошие результаты только для очень схожих по наборам слов текстов, в данном случае позволяют линейным моделям достаточно хорошо работать при классификации текстов.